{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "#### Discuss different approaches you could take to estimate which inventory fits a given client. Explain which data sources you considered and which approaches/algorithms are possible. Bonus points for using descriptive statistics to understand trade-offs between different approaches.\n",
    "\n",
    "At a high-level this assignment fits a canonical form in data science of designing a recommendation system.  The system is responsible for returning a predicted set of user-specific items of interest.  Classically, there are two ways of inferring user interest in an item: content-based and collaborative-based filtering.  In the first, item-to-item similarity is deduced, and items are suggested to a user based upon what they have evaluated highly in the past.  In the second user-to-user similarity is measured and used to advance item recommendations.\n",
    "\n",
    "For the specific problem of taking the data supplied and ultimately producing item recommendations on the basis of fit, the decision of which filtering strategy to pursue turns on a number of questions\n",
    "- What style or sku specific data is available.  For content-based filtering we need an explicit basis of features to paramatize the items, and this basis should be sufficient to explain user-item fit.\n",
    "- How are user-item interactions recorded in the data?  It appears that overall satisfaction is measured via a likert scale of \"loved it\", \"liked it\", \"just okay,\" however, we're exclusively interested in feedback as it pertains to clothing fit.  This is measured with a more complex relationship in the data wherein, under certain situations, fit satisfaction is recorded via a binary feature, and in the event of fit disatisfaction, more specific feedback is collected.  This response behavior needs to be marshalled into a single number indicating implicit fit feedback.  \n",
    "- How large is the dataset?  As mentioned above, collaborative filtering relies upon assessing user-to-user similarity, if the dataset is large then neighborhood methods which compute pairwise user-to-user distances across the full set of items will likely be too costly.\n",
    "- How much feedback is there for all the user-item combinations in the dataset?  The success of many recommendor algorithims depends upon the sparsity of the user-item matrix.\n",
    "- Is the problem of fit primarily one of \"discovery\" i.e. do we want to suggest items outside of a users typical ordering habits?  Or is it one of \"retriaval\" where the goal is to surface styles most similiar to what a user has ordered before?  \n",
    "- Are their \"exogenous\" features that the model should capture?  Generally, content-based filtering allows one to paramatize the items freely, but introducing user-based features is more difficult.  A similiar challenge exists for collobarative filtering.\n",
    "\n",
    "## Matrix factorization\n",
    "\n",
    "Note: my general approach is taken from this [2008 survery paper by Koren and Bell.](https://s3.amazonaws.com/academia.edu.documents/36167999/Collaborative-Filtering-_Koren-and-Bell_.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1524775559&Signature=%2B03E69kBr%2Fznn1sN4vk%2BoQ1shvI%3D&response-content-disposition=inline%3B%20filename%3DAdvances_in_Collaborative_Filtering.pdf)\n",
    "\n",
    "I choose to treat this as a collaborative filtering problem solved via matrix factorization.  Briefly, this approach assumes that the user-item matrix is a high-dimensional, rank-deficient representation of the data.    That is, there exists a basis in a lower dimensions that well paramatizes the users and items.  If we're succesful in recovering this basis, then we can use it to \"reconstruct\" the missing values in the user-item matrix.\n",
    "\n",
    "I was drawn to this approach for three reasons.\n",
    "- First, I was aware that this method has been popular recently for similiar types of recommendation problems.\n",
    "- Second, the dataset contains 35,000 unique users, 4,000 unique styles, and 24,167 unique skus.  Thus the dimensions of the problem are \"largish\" for a personal computer.  Indeed, I ruled out treating items at the sku level due to the resulting size of the interaction matrix.  Even just considering the problem at the style level, a dense matrix which encodes fit feedback with an integer value (assuming numpy's int64 format of 8 Bytes / interger value) would consume $35,000 \\times 4,000 \\times 8 \\approx 1 GB$ of memory.  Additionally, the measured sparsity for the user item matrix was about .018, which seemed to be comparable to the sparsity for other large scale collaborative filtering problems (https://www.quora.com/How-sparse-is-the-real-life-dataset-for-recommender-systems).  \n",
    "- Third, this approach makes it easy to introduce additional user specific features into the objective function in a theoretically consistent manner.  This has the added benefit of presenting a solution for the so-called \"cold start\" problem.  When there's insufficient item interaction data for a user, the model will make recommendations based upon learned baseline biases for the overall dataset and items, as well as initial user data (nominal size, height, weight, bmi).\n",
    "\n",
    "The problem may be mathmatically expressed as follows.  We wish to minimize the the difference between the original user-item matrix, $R$, and a reconstruction of it formed from a low rank factorization, $\\hat{R}$.  The objective function the takes the form: \n",
    "\n",
    "\\begin{alignat*}{2}\n",
    "&\\textrm{min} \\quad &&\\sum_{(u,i) \\in R} \\; (R_{ui} - \\hat{R}_{ui}) \\\\\n",
    "&\\textrm{subject to} \\quad &&\\textrm{Rank}\\left(\\hat{R}\\right)=k\n",
    "\\end{alignat*}\n",
    "\n",
    "where the elements of $\\hat{R}$ are expressed as\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu + b^i_i + b^u_u + q_i^T \\left(p_u + |N(u)|^{-.5} \\sum_{j \\in N(u)} y_j \\right)\n",
    "$$\n",
    "\n",
    "Here, $\\mu \\in \\mathbb{R}$, $b_i \\in \\mathbb{R}^k$, and $b_u \\in \\mathbb{R}^k$ make up the baseline model for the user-item rating.  The scalar $\\mu$ represents an overall bias for the entire matrix, and corresponds to how well clothing fits users on average.  Similarly, the scalars $b^i_i$ and $b^u_u$ denote the average biases for item $i$ and user $u$.  The interaction of a specific user and item is captured through the inner product of the item's latent feature vector, $q_i \\in \\mathbb{R}^k$ and the \"augmented\" latent user vector given by $p_u + |N(u)|^{-.5} \\sum_{j \\in N(u)} y_j$, where $p_u$ is the representation of the user in the latent space learned from their item interactions, and the $y_j$ are the latent factor representations of additional user information (size, height, ... etc).  $N(u)$ justs denotes the cardinality of the set of additional user features and is used to normalize the resultant vector for stability (Koren & Bell).\n",
    "\n",
    "The objective function can now be written more explicitly as\n",
    "\n",
    "\\begin{alignat*}{2}\n",
    "&\\min_{\\mu, b_i, b_u, Q, P, Y} \\quad &&\\sum_{(u,i) \\in R} \\; r_{ui} -\\mu + b^i_i + b^u_u + q_i^T \\left(p_u + |N(u)|^{-.5} \\sum_{j \\in N(u)} y_j \\right) \\\\\n",
    "&\\textrm{subject to} \\quad && Q \\in \\mathbb{R}^{m \\times k}, \\; P \\in \\mathbb{R}^{k \\times n}, Y \\in \\mathbb{R}^{k \\times N(u_1, ... u_m)}\n",
    "\\end{alignat*}\n",
    "\n",
    "The minimizers $\\mu^*$, $b^*_i$, $b^*_u$, $Q^*,$ $P^*$, $Y^*$ can be found through different optimization routines.  I choose SGD due to ease-of-implementation\n",
    "\n",
    "# Question 2\n",
    "##### Choose the approach you think is best suited for an MVP. The goal is to find an algorithm that is relatively easy to implement, and still provides significant value for our customers. Implement the algorithm as a function that returns an orderd list of styles for each user fit_reco(user_id) = [\"CEL13_1\", \"VIN69_XS\", ...] . In that ordered list, the first sku is our best fit recommendation for the client, and skus lower on the list are expected to fit less well.\n",
    "\n",
    "The remainder of this notebook is structured in a couple of sequential steps to produce a model object with the desired method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and jupyter nb settings\n",
    "# best params k=70, alpha = .002, beta=.001, beta=.05\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\n",
    "'''\n",
    "project/\n",
    "|-- notebooks/\n",
    "|   |-- rtr_data_assignment.ipynb\n",
    "|-- data/\n",
    "|   |-- orders.csv\n",
    "|   |-- reviews.csv\n",
    "|   |-- size_mapping.csv\n",
    "|   |-- user_attributes.csv\n",
    "'''\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.dirname(NOTEBOOK_DIR)\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data/\")\n",
    "\n",
    "orders = pd.read_csv(os.path.join(DATA_DIR, \"orders.csv\"))\n",
    "reviews = pd.read_csv(os.path.join(DATA_DIR, \"reviews.csv\"))\n",
    "#size_mappings = pd.read_csv(SIZE_MAPPINGS) //ended up not using this\n",
    "style_attr = pd.read_csv(os.path.join(DATA_DIR, \"style_attributes.csv\"))\n",
    "user_attr = pd.read_csv(os.path.join(DATA_DIR, \"user_attributes.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(orders_df, reviews_df, thin_users, thin_styles):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocesses data and returns a dense  matrix factorization to predict empty\n",
    "    entries in a matrix.\n",
    "\n",
    "    Arguments\n",
    "    - R (UserStyleMat)   : user-item rating matrix\n",
    "    - K (int)       : number of latent dimensions\n",
    "    - alpha (float) : learning rate\n",
    "    - beta (float)  : regularization parameter\n",
    "    - iterations    : number of iterations to run for\n",
    "    \"\"\"\n",
    "        \n",
    "    unique_users = orders['user_id'].unique()\n",
    "    thinned_users = np.random.choice(unique_users, int(len(unique_users)*thin_users), replace=False)\n",
    "    \n",
    "    unique_styles = orders['style'].unique()\n",
    "    thinned_styles = np.random.choice(unique_styles, int(len(unique_styles)*thin_styles), replace=False)\n",
    "    \n",
    "    _orders_df = orders_df.copy()\n",
    "    _orders_df = _order_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    _reviews_df = reviews_df.copy()\n",
    "    _reviews_df = _reviews_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    _orders_df = _orders_df[_orders_df['user_id'].isin(thinned_users)]\n",
    "    _orders_df = _orders_df[_orders_df['style'].isin(thinned_styles)]\n",
    "    \n",
    "    _orders_df.set_index(\"order_id\", inplace=True)\n",
    "    joined = _reviews_df.join(_orders_df, how='left', on=\"order_id\")\n",
    "    joined = joined[['user_id','style','didnt_fit']]\n",
    "    joined['didnt_fit'] = joined['didnt_fit'].astype(int)\n",
    "    joined.loc[joined['didnt_fit'] == 0, 'didnt_fit'] = 10\n",
    "    return joined.groupby(['user_id','style'])['didnt_fit'].mean().unstack()\n",
    "\n",
    "def data2sparse(df, training_prop, testing_prop):\n",
    "    (x_inds, y_inds) = np.nonzero(~np.isnan(df.values))\n",
    "    n = len(x_inds)\n",
    "    inds = np.random.choice(n, int((training_prop+testing_prop)*n), replace=False)\n",
    "    train_inds = np.random.choice(\n",
    "        inds, int(training_prop/(training_prop + testing_prop)*len(inds)), replace=False\n",
    "    ) \n",
    "    inds = set(inds)\n",
    "    train_inds = set(train_inds)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    for i in range(n):\n",
    "        if i not in inds:\n",
    "            continue\n",
    "        else:\n",
    "            if i in train_inds:\n",
    "                train_x.append(x_inds[i])\n",
    "                train_y.append(y_inds[i])\n",
    "            else:\n",
    "                test_x.append(x_inds[i])\n",
    "                test_y.append(y_inds[i])\n",
    "\n",
    "    train = [train_x, train_y]\n",
    "    test = [test_x, test_y]\n",
    "    train_sparse = sparse.dok_matrix(sparse.coo_matrix((df.values[train], train), shape = df.shape))\n",
    "    test_sparse = sparse.dok_matrix(sparse.coo_matrix((df.values[test], test), shape = df.shape))\n",
    "    return (train_sparse, test_sparse)\n",
    "    \n",
    "# g = prepare_data(orders, reviews, thin_users=1, thin_styles=1)\n",
    "# print(g.shape)\n",
    "# (train_raw, test_raw) = data2sparse(g, .9, .1)\n",
    "# print(\"TRAINING SHAPE {}; NNZ: {}; Sparsity {:0.4f}%\".format(\n",
    "#     train_raw.shape, train_raw.nnz, 100*(1 - (train_raw.nnz / (train_raw.shape[0] * train_raw.shape[1]))))\n",
    "#      )\n",
    "# print(\"TESTING SHAPE {}; NNZ: {}; Sparsity {:0.4f}%\".format(\n",
    "#     test_raw.shape, test_raw.nnz, 100*(1 - (test_raw.nnz / (test_raw.shape[0] * test_raw.shape[1]))))\n",
    "#      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_attrib_dict(user_attr, grouped_df):\n",
    "    \n",
    "    SIZE_INCR = 1\n",
    "    HEIGHT_INCR = 1\n",
    "    WEIGHT_INCR = 2\n",
    "    BMI_INCR = 1\n",
    "    \n",
    "    _df = user_attr.copy()\n",
    "    _df['bmi'] = (_df['weight_lbs'] / _df['height_in'].pow(2))*703\n",
    "    _df['size_bin'] = np.floor((_df['standard_size']  - _df['standard_size'].min()) / SIZE_INCR)\n",
    "    _df['height_bin'] = np.floor((_df['height_in']  - _df['height_in'].min()) / HEIGHT_INCR)\n",
    "    _df['weight_bin'] = np.floor((_df['weight_lbs']  - _df['weight_lbs'].min()) / WEIGHT_INCR)\n",
    "    _df['bmi_bin'] = np.floor((_df['bmi']  - _df['bmi'].min()) / BMI_INCR)\n",
    "    _df.drop([\"standard_size\",\"height_in\",\"weight_lbs\",\"bmi\"], axis=1, inplace=True)\n",
    "    index_df = pd.DataFrame(grouped_df.index)\n",
    "    _df.set_index('user_id', inplace=True)\n",
    "    df = index_df.join(_df,on='user_id',how='left')\n",
    "    return(df.to_dict('records'))\n",
    "\n",
    "def make_userId2idx_dict(user_attr):\n",
    "    d = user_attr['user_id'].to_dict()\n",
    "    d = {v: k for k, v in d.items()}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserStyleMat(object):\n",
    "    '''\n",
    "    data structure with convenience functions for matrix factorization.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, user_attrib_dict, userId2idx_dict, style_names):\n",
    "        \n",
    "        self.data = data\n",
    "        self.user_attrib_dict = user_attrib_dict\n",
    "        self.style_names = style_names\n",
    "        self.userId2idx_dict = userId2idx_dict\n",
    "        \n",
    "        df = pd.DataFrame(user_attrib_dict)\n",
    "        \n",
    "        self.n_sizes = df['size_bin'].max()  + 1\n",
    "        self.n_heights = df['height_bin'].max()  + 1\n",
    "        self.n_weights = df['weight_bin'].max()  + 1\n",
    "        self.n_bmis = df['bmi_bin'].max()  + 1\n",
    "        \n",
    "    def get_user_params(self, idx):\n",
    "        return self.user_attrib_dict[idx]\n",
    "    \n",
    "    def userid2idx(self, user_id):\n",
    "        return self.userId2idx_dict[user_id]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(orders, reviews, user_attr, thin_users, thin_styles, training_prop, testing_prop):\n",
    "    \n",
    "    g = prepare_data(orders, reviews, thin_users=thin_users, thin_styles=thin_styles)\n",
    "    (train_raw, test_raw) = data2sparse(g, training_prop, testing_prop)\n",
    "    print(\"TRAINING SHAPE {}; NNZ: {}; Sparsity {:0.4f}%\".format(\n",
    "        train_raw.shape, train_raw.nnz, 100*(1 - (train_raw.nnz / (train_raw.shape[0] * train_raw.shape[1]))))\n",
    "         )\n",
    "    print(\"TESTING SHAPE {}; NNZ: {}; Sparsity {:0.4f}%\".format(\n",
    "        test_raw.shape, test_raw.nnz, 100*(1 - (test_raw.nnz / (test_raw.shape[0] * test_raw.shape[1]))))\n",
    "         )\n",
    "        \n",
    "    user_attrib_dict = make_user_attrib_dict(user_attr, g)\n",
    "    userId2idx_dict = make_userId2idx_dict(user_attr)\n",
    "    style_names = list(g.columns)\n",
    "    \n",
    "    train = UserStyleMat(train_raw, user_attrib_dict, userId2idx_dict, style_names)\n",
    "    test = UserStyleMat(test_raw, user_attrib_dict, userId2idx_dict, style_names)\n",
    "    \n",
    "    return(train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "\n",
    "    def __init__(self, training_USM, testing_USM, K, alpha, beta1, beta2, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "\n",
    "        Arguments\n",
    "        - R (UserStyleMat)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimensions\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        - iterations    : number of iterations to run for\n",
    "        \"\"\"\n",
    "                        \n",
    "        self.training_USM = training_USM\n",
    "        self.testing_USM = testing_USM\n",
    "        self.num_users, self.num_items = training_USM.data.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iterations = iterations\n",
    "        \n",
    "\n",
    "    def get_feature_vec(self, bin_idx, feature_vec):\n",
    "        \"\"\"\n",
    "        get the feature vector associated with a bin index.  If bin_indx is NaA return zeros\n",
    "        \"\"\"\n",
    "        if np.isnan(bin_idx):\n",
    "            vec = np.zeros(self.K)\n",
    "            indicator = 0\n",
    "        \n",
    "        else:\n",
    "            bin_idx = int(bin_idx)\n",
    "            vec = feature_vec[bin_idx, :]\n",
    "            indicator = 1\n",
    "        \n",
    "        return (vec, indicator)\n",
    "    \n",
    "    def set_feature_vec(self, bin_idx, feature_vec, val):\n",
    "        \"\"\"\n",
    "        set the feature vector at bin_idx to val.\n",
    "        \"\"\"\n",
    "        if np.isnan(bin_idx):\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            bin_idx = int(bin_idx)\n",
    "            feature_vec[bin_idx, :] = val\n",
    "        return\n",
    "    \n",
    "    def get_all_feature_vecs(self, user_idx):\n",
    "        \"\"\"\n",
    "        for a given user id, return all feature vectors and cardinality of this set.\n",
    "        \"\"\"\n",
    "        user_dict = self.training_USM.get_user_params(user_idx)\n",
    "        (size_vec, size_indic) = self.get_feature_vec(user_dict['size_bin'], self.sizes)\n",
    "        (height_vec, height_indic) = self.get_feature_vec(user_dict['height_bin'], self.heights)\n",
    "        (weight_vec, weight_indic) = self.get_feature_vec(user_dict['weight_bin'], self.weights)\n",
    "        (bmi_vec, bmi_indic) = self.get_feature_vec(user_dict['bmi_bin'], self.bmis)\n",
    "        \n",
    "        cardinality = size_indic + height_indic + weight_indic + bmi_indic\n",
    "        cardinality = max(cardinality, 1)\n",
    "        return(size_vec, height_vec, weight_vec, bmi_vec, cardinality)\n",
    "\n",
    "    def set_all_feature_vecs(self, user_idx, size_vals, height_vals, weight_vals, bmi_vals):\n",
    "        \"\"\"\n",
    "        set all feature vectors for a given user\n",
    "        \"\"\"\n",
    "        user_dict = self.training_USM.get_user_params(user_idx)\n",
    "        self.set_feature_vec(user_dict['size_bin'], self.sizes, size_vals)\n",
    "        self.set_feature_vec(user_dict['height_bin'], self.heights, height_vals)\n",
    "        self.set_feature_vec(user_dict['weight_bin'], self.weights, weight_vals)\n",
    "        self.set_feature_vec(user_dict['bmi_bin'], self.bmis, bmi_vals)\n",
    "        return\n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Training for k={}; alpha={}; beta1={}; beta2={}\".format(self.K, self.alpha, self.beta1, self.beta2))\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.training_USM.data)\n",
    "        \n",
    "        # Initialize the additional user latent feature matrices.\n",
    "        self.sizes = np.random.normal(scale=1./self.K, size=(int(self.training_USM.n_sizes), self.K))\n",
    "        self.heights = np.random.normal(scale=1./self.K, size=(int(self.training_USM.n_heights), self.K))\n",
    "        self.weights = np.random.normal(scale=1./self.K, size=(int(self.training_USM.n_weights), self.K))\n",
    "        self.bmis = np.random.normal(scale=1./self.K, size=(int(self.training_USM.n_bmis), self.K))\n",
    "\n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i[0][0], i[0][1], i[1])\n",
    "            for i in self.training_USM.data.items()\n",
    "        ]\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        self.training_process = []\n",
    "        rmse_train_baseline = self.rmse_baseline(self.training_USM.data)\n",
    "        rmse_test_baseline = self.rmse_baseline(self.testing_USM.data)\n",
    "        epoch = 0\n",
    "        exit_code = 0\n",
    "        while (epoch < self.iterations) and (exit_code == 0):\n",
    "            np.random.shuffle(self.samples)\n",
    "            exit_code = self.sgd()\n",
    "            rmse_train = self.rmse(self.training_USM.data)\n",
    "            rmse_test = self.rmse(self.testing_USM.data)\n",
    "            self.training_process.append((epoch, rmse_train, rmse_train_baseline, rmse_test, rmse_test_baseline))\n",
    "            epoch += 1\n",
    "            if (epoch) % 1 == 0:\n",
    "                print(\"Epoch: %d\\n\" \\\n",
    "                \"\\ttrain_err = %.4f; train_baseline_err = %.4f\\n\" \\\n",
    "                      \"\\ttest_err = %.4f; test_baseline_err = %.4f\" % (\n",
    "                          epoch, rmse_train, rmse_train_baseline, rmse_test, rmse_test_baseline)\n",
    "                     )\n",
    "\n",
    "            self.alpha = .9*self.alpha\n",
    "            \n",
    "        \n",
    "        test_errors = [tp[3] for tp in self.training_process]\n",
    "        best_test_error = min(test_errors)\n",
    "        print(\"BEST TEST: {}\".format(best_test_error))\n",
    "        return (best_test_error, ((self.K, self.alpha, self.beta1, self.beta2)))\n",
    "\n",
    "    def rmse(self, data):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        \n",
    "        error = 0\n",
    "        n = data.nnz\n",
    "        for (x, y) in data.keys():\n",
    "            (size_vec, height_vec, weight_vec, bmi_vec, cardinality) = self.get_all_feature_vecs(x)\n",
    "            user_vec = cardinality**(-.5)*(size_vec + height_vec + weight_vec + bmi_vec)\n",
    "            error += pow(data[x, y] - self.get_rating(x,y,user_vec), 2)\n",
    "        return np.sqrt(error/n)\n",
    "    \n",
    "    def rmse_baseline(self, data):\n",
    "        \"\"\"\n",
    "        compute rmse error w.r.t. a baseline predictor that always guess average value.\n",
    "        \"\"\"\n",
    "        error = 0\n",
    "        n = data.nnz\n",
    "        mean_nz = np.mean(list(data.values()))\n",
    "        for (x, y) in data.keys():\n",
    "            error += pow(data[x, y] - mean_nz, 2)\n",
    "        return np.sqrt(error/n)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic graident descent\n",
    "        \"\"\"\n",
    "        counter = 0\n",
    "        for i, j, r in self.samples:\n",
    "         \n",
    "            (size_vec, height_vec, weight_vec, bmi_vec, cardinality) = self.get_all_feature_vecs(i)\n",
    "            user_vec = cardinality**(-.5)*(size_vec + height_vec + weight_vec + bmi_vec)\n",
    "\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(i, j, user_vec)\n",
    "            e = (r - prediction)\n",
    "            if(np.isnan(e)):\n",
    "                print(\"Terminating SGD: Gradients became badly conditioned \" \\\n",
    "                      \"increase regularization or decrease stepsize\")\n",
    "                return(1)\n",
    "        \n",
    "            self.b_u[i] += self.alpha * (e - self.beta1 * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta1 * self.b_i[j])\n",
    "\n",
    "            # Update user and item latent feature matrices\n",
    "            self.Q[j, :] += self.alpha * (e * (self.P[i, :]+user_vec) - self.beta2 * self.Q[j,:])\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta2 * self.P[i,:])\n",
    "            \n",
    "            # update user features\n",
    "            size_vec += self.alpha * (e *self.Q[j, :] - self.beta2 * size_vec)\n",
    "            height_vec += self.alpha * (e *self.Q[j, :] - self.beta2 * height_vec)\n",
    "            weight_vec += self.alpha * (e *self.Q[j, :] - self.beta2 * weight_vec)\n",
    "            bmi_vec += self.alpha * (e *self.Q[j, :] - self.beta2 * bmi_vec)\n",
    "            \n",
    "            self.set_all_feature_vecs(i, size_vec, height_vec, weight_vec, bmi_vec)\n",
    "        return(0)\n",
    "\n",
    "    def get_rating(self, i, j, user_vec):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"           \n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + (self.P[i, :] + user_vec).dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def predict_for_user(self, user_id):\n",
    "        \"\"\"\n",
    "        Get items sorted by predicted fit for a user in training set.  User bias and \n",
    "        \"\"\"\n",
    "        i = self.training_USM.userid2idx(user_id)\n",
    "        if(not i):\n",
    "            raise ValueError('User Id not found in data')\n",
    "        else:\n",
    "            (size_vec, height_vec, weight_vec, bmi_vec, cardinality) = self.get_all_feature_vecs(i)\n",
    "            user_vec = cardinality**(-.5)*(size_vec + height_vec + weight_vec + bmi_vec)\n",
    "            \n",
    "            predictions = self.b + self.b_u[i] + self.b_i + np.matmul(self.Q, (self.P[i, :] + user_vec).T)\n",
    "            d = {'Score': predictions, 'Style': self.training_USM.style_names}\n",
    "            return pd.DataFrame(d).sort_values('Score')\n",
    "            \n",
    "        \n",
    "\n",
    "#     def full_matrix(self):\n",
    "#         \"\"\"\n",
    "#         Computer the full matrix using the resultant biases, P and Q\n",
    "#         \"\"\"\n",
    "#         return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SHAPE (6890, 800); NNZ: 38267; Sparsity 99.3058%\n",
      "TESTING SHAPE (6890, 800); NNZ: 9567; Sparsity 99.8264%\n"
     ]
    }
   ],
   "source": [
    "grid_train, grid_test = data_pipeline(orders, reviews, user_attr, .2, .2, .8, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gridsearch(train, test):\n",
    "    best = np.inf\n",
    "    ranks = [60,70,80]\n",
    "    alphas = [.0025, .005, .0075]\n",
    "    beta1s = [.0008, .001, .0025, .004]\n",
    "    beta2s = [.04, .05, .06, .08]\n",
    "    for r in ranks:\n",
    "        for a in alphas:\n",
    "            for b1 in beta1s:\n",
    "                for b2 in beta2s:\n",
    "                    model = MF(train, test, r, a, b1, b2, 30)\n",
    "                    (train_err, params) = model.train()\n",
    "                    if train_err < best:\n",
    "                        best = train_err\n",
    "                        best_params = params\n",
    "                    print(\"BEST SO FAR {} WITH PARAMS {}\".format(best, best_params))\n",
    "    \n",
    "    return best, best_params\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for k=60; alpha=0.0025; beta1=0.0008; beta2=0.04\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7777; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.8102; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.7009; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7555; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6531; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7214; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6246; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7053; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6085; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6992; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5881; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6885; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5790; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6853; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5699; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6809; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5611; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6769; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5536; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6754; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5504; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6745; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5447; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6717; test_baseline_err = 2.8001\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5384; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6685; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5359; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6683; test_baseline_err = 2.8001\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5336; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6694; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5287; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6665; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5295; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6695; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5224; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6652; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5212; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6654; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5193; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6650; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5173; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6646; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5151; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6636; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5139; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6635; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5122; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6631; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5116; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6633; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5108; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6636; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5093; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6630; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5105; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6642; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5079; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6628; test_baseline_err = 2.8001\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5070; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6628; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.6628183328325497\n",
      "BEST SO FAR 2.6628183328325497 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.04)\n",
      "Training for k=60; alpha=0.0025; beta1=0.0008; beta2=0.05\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7669; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.8004; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6945; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7452; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6469; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7185; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6243; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7072; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6028; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6965; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5860; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6849; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5794; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6827; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5729; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6820; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5636; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6782; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5565; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6743; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5510; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6711; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5472; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6706; test_baseline_err = 2.8001\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5434; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6692; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5421; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6694; test_baseline_err = 2.8001\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5366; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6663; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5383; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6692; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5322; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6647; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5334; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6674; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5283; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6647; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5274; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6644; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5262; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6642; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5274; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6663; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5234; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6636; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5234; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6641; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5226; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6640; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5206; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6627; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5191; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6622; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5198; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6632; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5187; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6628; test_baseline_err = 2.8001\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5181; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6626; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.6621733183972496\n",
      "BEST SO FAR 2.6621733183972496 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.05)\n",
      "Training for k=60; alpha=0.0025; beta1=0.0008; beta2=0.06\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7586; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7917; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6937; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7485; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6492; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7196; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6192; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7027; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6049; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6973; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5885; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6869; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5790; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6825; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5683; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6765; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5670; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6784; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5628; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6771; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5529; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6704; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5514; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6721; test_baseline_err = 2.8001\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5513; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6728; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5448; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6688; test_baseline_err = 2.8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n",
      "\ttrain_err = 2.5436; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6687; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5393; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6661; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5365; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6657; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5360; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6649; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5350; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6654; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5328; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6644; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5344; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6667; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5332; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6661; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5294; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6634; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5284; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6634; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5289; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6643; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5287; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6645; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5272; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6637; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5258; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6630; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5254; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6629; test_baseline_err = 2.8001\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5258; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6634; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.6629214472270677\n",
      "BEST SO FAR 2.6621733183972496 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.05)\n",
      "Training for k=60; alpha=0.0025; beta1=0.0008; beta2=0.08\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7510; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7880; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6999; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7577; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6486; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7215; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6219; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7047; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6021; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6945; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5933; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6904; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5825; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6844; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5736; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6802; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5688; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6774; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5658; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6777; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5612; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6753; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5556; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6714; test_baseline_err = 2.8001\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5535; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6712; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5521; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6710; test_baseline_err = 2.8001\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5492; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6698; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5487; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6700; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5449; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6677; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5430; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6665; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5437; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6679; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5403; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6656; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5402; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6656; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5410; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6675; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5389; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6658; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5387; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6655; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5370; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6650; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5371; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6652; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5352; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6636; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5361; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6647; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5360; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6650; test_baseline_err = 2.8001\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5347; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6642; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.6636006693450685\n",
      "BEST SO FAR 2.6621733183972496 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.05)\n",
      "Training for k=60; alpha=0.0025; beta1=0.001; beta2=0.04\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7846; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.8228; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6971; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7506; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6567; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7255; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6263; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7100; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6085; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6987; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5953; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6948; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5832; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6883; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5675; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6787; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5586; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6750; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5547; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6760; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5491; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6734; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5434; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6718; test_baseline_err = 2.8001\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5368; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6687; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5352; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6694; test_baseline_err = 2.8001\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5319; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6675; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5278; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6666; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5257; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6671; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5226; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6657; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5196; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6648; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5182; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6648; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5165; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6647; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5150; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6645; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5133; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6639; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5117; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6637; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5106; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6638; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5103; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6638; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5077; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6627; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5077; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6634; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5067; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6634; test_baseline_err = 2.8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\n",
      "\ttrain_err = 2.5053; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6625; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.662468206505342\n",
      "BEST SO FAR 2.6621733183972496 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.05)\n",
      "Training for k=60; alpha=0.0025; beta1=0.001; beta2=0.05\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7668; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.8028; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6956; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7499; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6545; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7265; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6251; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7071; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6006; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6936; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5884; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6869; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5794; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6836; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5678; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6766; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5637; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6770; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5614; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6784; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5519; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6716; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5520; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6744; test_baseline_err = 2.8001\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5479; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6727; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5430; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6696; test_baseline_err = 2.8001\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5382; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6673; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5370; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6668; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5332; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6660; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5311; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6654; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5292; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6651; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5289; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6651; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5264; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6638; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5254; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6643; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5237; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6635; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5234; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6635; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5225; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6635; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5215; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6632; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5211; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6631; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5217; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6645; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5195; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6628; test_baseline_err = 2.8001\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5185; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6622; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.6622160075318297\n",
      "BEST SO FAR 2.6621733183972496 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.05)\n",
      "Training for k=60; alpha=0.0025; beta1=0.001; beta2=0.06\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7591; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7961; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6956; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7506; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6498; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7206; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6219; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7056; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6013; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6946; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5859; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6848; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5770; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6820; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5688; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6771; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5687; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6810; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5596; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6745; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5539; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6719; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5535; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6738; test_baseline_err = 2.8001\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5460; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6679; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5457; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6683; test_baseline_err = 2.8001\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5456; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6701; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5398; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6664; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5378; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6656; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5375; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6673; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5364; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6670; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5335; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6649; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5321; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6640; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5316; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6642; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5309; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6645; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5330; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6671; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5284; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6636; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5273; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6625; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5278; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6638; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5280; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6644; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5271; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6638; test_baseline_err = 2.8001\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5263; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6634; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.6625117707426647\n",
      "BEST SO FAR 2.6621733183972496 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.05)\n",
      "Training for k=60; alpha=0.0025; beta1=0.001; beta2=0.08\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7489; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7886; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6862; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7434; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6500; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7238; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6229; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7053; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6044; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6961; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5900; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6889; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5816; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6870; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5783; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6848; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5685; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6766; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5693; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6803; test_baseline_err = 2.8001\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5640; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6784; test_baseline_err = 2.8001\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5548; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6711; test_baseline_err = 2.8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "\ttrain_err = 2.5563; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6747; test_baseline_err = 2.8001\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5495; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6691; test_baseline_err = 2.8001\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5529; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6733; test_baseline_err = 2.8001\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5457; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6685; test_baseline_err = 2.8001\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5441; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6676; test_baseline_err = 2.8001\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5440; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6680; test_baseline_err = 2.8001\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5418; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6669; test_baseline_err = 2.8001\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5414; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6668; test_baseline_err = 2.8001\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5406; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6666; test_baseline_err = 2.8001\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5405; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6673; test_baseline_err = 2.8001\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5375; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6652; test_baseline_err = 2.8001\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5392; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6671; test_baseline_err = 2.8001\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5367; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6646; test_baseline_err = 2.8001\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5370; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6658; test_baseline_err = 2.8001\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5363; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6653; test_baseline_err = 2.8001\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5348; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6644; test_baseline_err = 2.8001\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5355; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6650; test_baseline_err = 2.8001\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5357; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6658; test_baseline_err = 2.8001\n",
      "BEST TEST: 2.664361205264392\n",
      "BEST SO FAR 2.6621733183972496 WITH PARAMS (60, 0.00010597789568804063, 0.0008, 0.05)\n",
      "Training for k=60; alpha=0.0025; beta1=0.0025; beta2=0.04\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7790; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.8125; test_baseline_err = 2.8001\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6984; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7531; test_baseline_err = 2.8001\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6614; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7304; test_baseline_err = 2.8001\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6249; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.7075; test_baseline_err = 2.8001\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.6065; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6999; test_baseline_err = 2.8001\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5869; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6873; test_baseline_err = 2.8001\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5766; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6829; test_baseline_err = 2.8001\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5672; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6804; test_baseline_err = 2.8001\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5675; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6829; test_baseline_err = 2.8001\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5565; train_baseline_err = 2.7861\n",
      "\ttest_err = 2.6772; test_baseline_err = 2.8001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-08f46739baf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Best (80, 0.0075, 0.001, 0.08)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-85fb2ba4f3eb>\u001b[0m in \u001b[0;36mrun_gridsearch\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeta2s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtrain_err\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-8b0294d91358>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexit_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mrmse_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_USM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mrmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting_USM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-8b0294d91358>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0msize_vec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mheight_vec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheight_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mweight_vec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mbmi_vec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbmi_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Best (80, 0.0075, 0.001, 0.08)\n",
    "# (60, 0.00010597789568804063, 0.0008, 0.05)\n",
    "run_gridsearch(grid_train, grid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SHAPE (35000, 4000); NNZ: 930554; Sparsity 99.3353%\n",
      "TESTING SHAPE (35000, 4000); NNZ: 232639; Sparsity 99.8338%\n",
      "Training for k=80; alpha=0.004; beta1=0.001; beta2=0.1\n",
      "Epoch: 1\n",
      "\ttrain_err = 2.7516; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.7942; test_baseline_err = 2.7907\n",
      "Epoch: 2\n",
      "\ttrain_err = 2.6725; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.7436; test_baseline_err = 2.7907\n",
      "Epoch: 3\n",
      "\ttrain_err = 2.6351; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.7221; test_baseline_err = 2.7907\n",
      "Epoch: 4\n",
      "\ttrain_err = 2.6031; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.7025; test_baseline_err = 2.7907\n",
      "Epoch: 5\n",
      "\ttrain_err = 2.5875; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6942; test_baseline_err = 2.7907\n",
      "Epoch: 6\n",
      "\ttrain_err = 2.5722; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6845; test_baseline_err = 2.7907\n",
      "Epoch: 7\n",
      "\ttrain_err = 2.5688; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6851; test_baseline_err = 2.7907\n",
      "Epoch: 8\n",
      "\ttrain_err = 2.5583; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6794; test_baseline_err = 2.7907\n",
      "Epoch: 9\n",
      "\ttrain_err = 2.5501; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6763; test_baseline_err = 2.7907\n",
      "Epoch: 10\n",
      "\ttrain_err = 2.5589; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6865; test_baseline_err = 2.7907\n",
      "Epoch: 11\n",
      "\ttrain_err = 2.5428; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6735; test_baseline_err = 2.7907\n",
      "Epoch: 12\n",
      "\ttrain_err = 2.5334; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6674; test_baseline_err = 2.7907\n",
      "Epoch: 13\n",
      "\ttrain_err = 2.5340; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6702; test_baseline_err = 2.7907\n",
      "Epoch: 14\n",
      "\ttrain_err = 2.5316; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6716; test_baseline_err = 2.7907\n",
      "Epoch: 15\n",
      "\ttrain_err = 2.5241; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6657; test_baseline_err = 2.7907\n",
      "Epoch: 16\n",
      "\ttrain_err = 2.5226; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6664; test_baseline_err = 2.7907\n",
      "Epoch: 17\n",
      "\ttrain_err = 2.5215; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6667; test_baseline_err = 2.7907\n",
      "Epoch: 18\n",
      "\ttrain_err = 2.5155; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6626; test_baseline_err = 2.7907\n",
      "Epoch: 19\n",
      "\ttrain_err = 2.5131; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6615; test_baseline_err = 2.7907\n",
      "Epoch: 20\n",
      "\ttrain_err = 2.5152; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6651; test_baseline_err = 2.7907\n",
      "Epoch: 21\n",
      "\ttrain_err = 2.5106; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6621; test_baseline_err = 2.7907\n",
      "Epoch: 22\n",
      "\ttrain_err = 2.5106; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6641; test_baseline_err = 2.7907\n",
      "Epoch: 23\n",
      "\ttrain_err = 2.5074; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6616; test_baseline_err = 2.7907\n",
      "Epoch: 24\n",
      "\ttrain_err = 2.5063; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6620; test_baseline_err = 2.7907\n",
      "Epoch: 25\n",
      "\ttrain_err = 2.5046; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6602; test_baseline_err = 2.7907\n",
      "Epoch: 26\n",
      "\ttrain_err = 2.5046; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6614; test_baseline_err = 2.7907\n",
      "Epoch: 27\n",
      "\ttrain_err = 2.5034; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6606; test_baseline_err = 2.7907\n",
      "Epoch: 28\n",
      "\ttrain_err = 2.5020; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6604; test_baseline_err = 2.7907\n",
      "Epoch: 29\n",
      "\ttrain_err = 2.5029; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6616; test_baseline_err = 2.7907\n",
      "Epoch: 30\n",
      "\ttrain_err = 2.5007; train_baseline_err = 2.7867\n",
      "\ttest_err = 2.6603; test_baseline_err = 2.7907\n",
      "BEST TEST: 2.660245679210571\n",
      "[(0, 2.7516134804888237, 2.7866762824759475, 2.794216197890003, 2.790688207558774), (1, 2.6725092849752032, 2.7866762824759475, 2.743649274870487, 2.790688207558774), (2, 2.635076891527005, 2.7866762824759475, 2.722057105288418, 2.790688207558774), (3, 2.60308608967736, 2.7866762824759475, 2.702470803333369, 2.790688207558774), (4, 2.5874693272686797, 2.7866762824759475, 2.6941664186327494, 2.790688207558774), (5, 2.5721908236460904, 2.7866762824759475, 2.6844740300446825, 2.790688207558774), (6, 2.5687793889853507, 2.7866762824759475, 2.6851003810019787, 2.790688207558774), (7, 2.558283033571159, 2.7866762824759475, 2.679408000719126, 2.790688207558774), (8, 2.5501211545998803, 2.7866762824759475, 2.6763104099862, 2.790688207558774), (9, 2.5588631697693502, 2.7866762824759475, 2.686538398740518, 2.790688207558774), (10, 2.542769906413823, 2.7866762824759475, 2.6735493387506, 2.790688207558774), (11, 2.5334073685753724, 2.7866762824759475, 2.6673509072226516, 2.790688207558774), (12, 2.533979060581722, 2.7866762824759475, 2.670241443328074, 2.790688207558774), (13, 2.5315662559220553, 2.7866762824759475, 2.6715955796413025, 2.790688207558774), (14, 2.52411465135681, 2.7866762824759475, 2.665687452287019, 2.790688207558774), (15, 2.522552563554451, 2.7866762824759475, 2.666388208360501, 2.790688207558774), (16, 2.52149278296415, 2.7866762824759475, 2.666710514505216, 2.790688207558774), (17, 2.515466996006298, 2.7866762824759475, 2.662625461040616, 2.790688207558774), (18, 2.5130693013256327, 2.7866762824759475, 2.661503270546316, 2.790688207558774), (19, 2.5151860671449464, 2.7866762824759475, 2.6651442891231594, 2.790688207558774), (20, 2.510628935035648, 2.7866762824759475, 2.662131628818547, 2.790688207558774), (21, 2.5106101599885395, 2.7866762824759475, 2.664121505750752, 2.790688207558774), (22, 2.507429042905795, 2.7866762824759475, 2.6616284691263123, 2.790688207558774), (23, 2.5063289782319713, 2.7866762824759475, 2.6620212227905387, 2.790688207558774), (24, 2.5046372810295794, 2.7866762824759475, 2.660245679210571, 2.790688207558774), (25, 2.504581949537805, 2.7866762824759475, 2.661378439155237, 2.790688207558774), (26, 2.503447565201395, 2.7866762824759475, 2.660588998380849, 2.790688207558774), (27, 2.501959000447471, 2.7866762824759475, 2.6604487840817646, 2.790688207558774), (28, 2.5028682083645446, 2.7866762824759475, 2.6615787332187533, 2.790688207558774), (29, 2.5007067362485285, 2.7866762824759475, 2.660329665560181, 2.790688207558774)]\n"
     ]
    }
   ],
   "source": [
    "full_train, full_test = data_pipeline(orders, reviews, user_attr, 1, 1, .8, .2)\n",
    "#model = MF(full_train, full_test, 80, 0.004, 0.001, 0.1, 30)\n",
    "model = MF(full_train, full_test, 80, 0.004, 0.001, 0.1, 30)\n",
    "model.train()\n",
    "print(model.training_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = \"000966f4-c977-3a9d-8477-8825fa6084bb\"\n",
    "def make_user_result_plot(user_id, order, reviews):\n",
    "    preds = model.predict_for_user(user_id)\n",
    "    #plt.xticks(preds['Style'], preds.index.values)\n",
    "    plt.plot(preds['Style'], preds['Score'])\n",
    "    #preds.set_index('Style', inplace=True)\n",
    "    #p = preds.plot()\n",
    "    \n",
    "#     user_orders = orders[orders['user_id'] == user_id]\n",
    "#     user_reviews = reviews[reviews['order_id'].isin(user_orders['order_id'])]\n",
    "#     user_reviews.set_index('order_id', inplace=True)\n",
    "#     joined = user_orders.join(user_reviews, how='left', on='order_id')\n",
    "#     joined = joined[['style', 'didnt_fit']]\n",
    "#     joined = joined.rename(index=str, columns={\"style\": \"Style\"})\n",
    "#     joined.set_index('Style', inplace=True)\n",
    "#     preds = preds.join(joined, how='left', on='Style')\n",
    "#     preds['Score'].plot()\n",
    "\n",
    "make_user_result_plot(uid, orders, reviews)\n",
    "#user_orders.set_index('order_id', inplace=True)\n",
    "#user_orders.join(reviews, how='left', on='order_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XXWd//HXJzf73iVJm6YL0AVattJQQHZGZBdRZFNURgdxZARlZlx+MyPqOOOMIy6gA6gMosheFBRZlH2xkJSWbkBLKW2aNE2bLtnXz++PcwKXNDe5adPe5N738/G4j9yc8z3nfr73nPs5537P93yvuTsiIpI60hIdgIiI7F9K/CIiKUaJX0QkxSjxi4ikGCV+EZEUo8QvIpJilPgl6ZjZzWb2rwl43S+YWb2ZNZvZhP39+rGMxriGs40StT2TmrvrEeMBrAfagOaox02Jjms0P4Drgd9E/e/AzH34ep8Bnh8F9c4I95UjBinzWeB1oAmoBx4BCqLmVwJ/ALYDO4BVwHeBcVF17YnaF98G/g+YvTdx7UFd1wMfTPR7nsBtPSr2ub156Ix/aOe5e37U4+qBCplZejzTBjPc8sNct5nZmNre+/L92AfKgGxg5UAzzexk4D+AS929ADgEuCdq/geAp4EXgIPdvRg4E+gGjoha1Uvung8UAR8kSOrVZnbonsQ1mD3dZ8bYdktNiT7yjOYHg5zZEBz1XwB+CGwD/j3GtDTgX4B3gC3AHUBRuI4ZBGfEnwU2AM8O8DqrgXOj/k8HGoCjwv+PBV4kOENcBpwSVfZpgjPGFwgSxMwwxnUEZ51vA58Iy17P+8/U+2JLj6rvbssNEO+76wGeDdfRQnCGenE4/VxgaRjzi8Dh/d7zrwKvAR1hfb8GvBW+9irggrDsIUA7750F7win3w78e9Q6/w5YCzQCDwHlUfMcuApYE8bzU8Bi1C0L+BFQGz5+FE6bHdbRwzieHGDZfwR+N8i+9jxw4xD742cY4EyT4FvC/QNMHzAu4APAK8DO8O8HBttn+q3z10Av730T/mdi7MfAfcDm8HWeBeZFrefdbQScAtQA1xF8RuqAK/aw7ATgYWBXWLd/H+g9C8tmA78h+KzuCMuXhfOKgF+G698UridCjH1urD0SHsBofjB04u8G/oEgOeXEmPa3BEnnQCAfWAT8OlxH3wfmDiAPyBngdf4NuDPq/3OA1eHzKeFOezbBAeb08P+ScP7T4QdxXhhPUfiBmBPOn9z3YWSQxB/GNuByA8Tbfz3va+oB5ocf2GPCD9Knw/c5K+o9XwpM7Xs/gI8D5WEdLyZIZpOjtsPz/WK4nfcSxWnAVuAogiR9I1EH2DC+PwDFwDSCg+qZMer2beCvQClQQnDQ+k7/9yvGsicSJMtvAcf31Tecl0eQSE4ZYn/cra7h9L8F6mMs8764gPEETUmXh9v20vD/CTH2mYyhPhfE2I/DuAp474C5NMY2OoXgc/Ntgqaps4FW3mviGk7Zu8NHLjAX2DjQexaW/TzBQSKXYF9cABSG8x4EbgnrUwq8DHx+sO0wlh5j6qt/gvzOzHZEPf4ual6tu9/o7t3u3hZj2ieAG9x9nbs3A18HLun3dfh6d2+JWke03wIfNrPc8P/LgLvC558EHnH3R9y9192fAKoIPgx9bnf3le7eTfCB6QUONbMcd69z93ibAPZ0uf6uBG5x98Xu3uPuvyI4sz82qsxP3H1j3/vh7ve5e21Yx3sIzs4Xxvl6nwBuc/cl7t5B8P4fZ2Yzosp8z913uPsG4CngyEHW9W133+LuDQRJ/PJ4gnD354CPEhyA/ghsM7MbzCwCjCM4qG3uK29m/x3uby1m9i9DrL6WIKHH4xxgjbv/OtxH7yK47nBeVJl39xl374pzvdBvP3b329y9KXzfrweOMLOiGMt2Eby3Xe7+CMHZ9JzhlA3fy48B33T3VndfBfxqkHi7CL4hzAz3xWp332VmZQSfoWvD+mwh+BZ/yTDei1FNiX9oH3H34qjHz6PmbRygfP9p5QTNPH3eITiTKhtiPQC4+1qC5p7zwuT/YYKDAcB04OPRBybgBIIz8t3W7e4tBGfMVwF1ZvZHMzs41mvv7XIxTAeu6xfzVIL3abeYAczsU2a2NKr8ocDEOF/vfe9/ePDdRvBtqc/mqOetBN/MhlxX+Lw8RtnduPuf3P08giR9PsGZ4+cIzrh7idpu7v7PHrTzP0iwvwxmCkEzVjz614Hw/+j3I+b+OIR3lzOziJl9z8zeMrNdBN8SIPZ22xaenPQZbDvEKltC8F5Fxz9YXX4NPAbcbWa14cE2g2AfzSDY1/v2uVsIzvyTghL/3hloaNP+02oJdqQ+0wjOvOuHWE+0uwi+kp8PrAoPBhDs1L/ud2DKc/fvxVq3uz/m7qcTJJnXgb4DWQvBV94+k+Jcbrg2At/tF3NueOa5W8xmNj18rasJmiOKgRWADVS/Abzv/TezPIKzvE17EPtA27J2uCsJv7n8BXgSODQ8sC4m+EawJy4AnouzbP86QFCP6PdjqPc01vzo6ZcR7K8fJGhinBFON/adBoLPVkXUtKmxCoffGL7l7nMJrnucC3yKYB/tACZG7aOF7j6vb9F9E/7+o8S/790FfNnMDjCzfIKeHff0O2MZyt3Ah4Av8N7ZPgQXps4zszPCM6xsMzvFzCoGWomZlZnZ+WHy6yD4itwbzl4KnGRm08Kv41+Pc7mh1BNc3+jzc+AqMzsm7DWSZ2bnmFlBjOXzCD5oDWEsVxCc8Uevv8LMMmMsfxdwhZkdaWZZBO//YndfH2f8/df1L2ZWYmYTCa6//CaeBcP37xIzGxfWeyFwMsE1Awgukv6tmX3NzErDZSqAA2KsLxLuUzcStHt/K846PALMNrPLzCzdzC4maAv/Q5zLw+7bdCAFBPvKNoITiv8Yxvr3iLv3EFxDu97McsNvpZ+KVd7MTjWzw8Imol0ETT+97l4HPA78wMwKzSzNzA4Ke2bB0PvcqKfEP7SHwxtf+h4PDnP52wi+Uj5L0BumneDib9zCHfElgrOSe6KmbyQ4q/oGQWLcCPwTsbdrGvAVgrO+RoLE84VwXU+E634NqOb9iSDmcnG4HvhV+JX5InevIuhlcxNBE8dagiaPWHVfBfyAoP71wGEEPU76PEnQVXGzmW0dYPk/A/8KPEDQQ+Mg9ryt9t8JrqG8BiwHloTT4rGdoN5rCJLMb4Dvu/udYZzPE1yIPgl4M2xeeJTgYuuNUes5zsyaw3U8DRQCR7v78niCcPdtBGe21xEk5X8m6DW223s3iP8kOADuMLN/jFHmDoImpE0EPbH+GqPcSLua4BvGZoLP3V0EB6CBTALuJ3gvVwPPhMtAcMDIJIh9e1iurylu0H1uLDD3Mf+tRURkQGb2X8Akd/90omMZTXTGLyJJw8wONrPDo5rTPktwgVyi6A47EUkmBQTNO+UETYM/AH6f0IhGITX1iIikmCGbesxsqpk9ZWarzGylmV0zQJkiM3vYzJaFZa6ImvdpM1sTPtTOJiKSYEOe8ZvZZILb45eEXe6qCW5qWhVV5hsE48981cxKgDcIrpjnE/SCqCToklcNLHD37YO95sSJE33GjBl7XisRkRRTXV291d1L4ik7ZBt/2JWwLnzeZGarCe7yWxVdDCgwMyNI9o0EN1KcATzh7o0AZvYEwYiD0Tfr7GbGjBlUVVXFE7+IiABm1v+O7JiG1avHgvFN5hPcZRjtJoJR62oJ+jdf4+69BAeI6Fuma3j/reHR677SzKrMrKqhoWE4YYmIyDDEnfjDu04fIBi4aFe/2WcQ3PlZTjDA1U1mVjicQNz9VnevdPfKkpK4vq2IiMgeiCvxhwMXPUAwPPCiAYpcASzywFqCO1QPJrhrL3qsjAr2bIwUEREZIfH06jGCHyRY7e43xCi2AfibsHwZwXCq6whGvvtQOD7JOILxZh4bicBFRGTPxHMD1/EEY44vN7Ol4bRvEIzoh7vfDHwHuN3MlhOMvvfVvrE/zOw7BL9sA8EY2vEOHysiIvtAPL16nmeIoVTdvZbgbH6gebcRDFQmIiKjgMbqERFJMck1Vs+fvgab4xqdVkRk9Jl0GJz1vaHL7SWd8YuIpJjkOuPfD0dKEZGxTmf8IiIpRolfRCTFKPGLiKQYJX4RkRSjxC8ikmKU+EVEUowSv4hIilHiFxFJMUr8IiIpRolfRCTFKPGLiKQYJX4RkRSjxC8ikmKU+EVEUowSv4hIilHiFxFJMUr8IiIpRolfRCTFKPGLiKQYJX4RkRQz5I+tm9lU4A6gDHDgVnf/cb8y/wR8ImqdhwAl7t5oZuuBJqAH6Hb3ypELX0REhmvIxA90A9e5+xIzKwCqzewJd1/VV8Ddvw98H8DMzgO+7O6NUes41d23jmTgIiKyZ4Zs6nH3OndfEj5vAlYDUwZZ5FLgrpEJT0RERtqw2vjNbAYwH1gcY34ucCbwQNRkBx43s2ozu3KQdV9pZlVmVtXQ0DCcsEREZBjiTvxmlk+Q0K91910xip0HvNCvmecEdz8KOAv4opmdNNCC7n6ru1e6e2VJSUm8Yb2rq6eX8296np8/u27Yy4qIpJK4Er+ZZRAk/TvdfdEgRS+hXzOPu28K/24BHgQW7lmog8uIpLG9tYulG3fsi9WLiCSNIRO/mRnwS2C1u98wSLki4GTg91HT8sILwphZHvAhYMXeBh3LvPJCVtXF+jIiIiIQX6+e44HLgeVmtjSc9g1gGoC73xxOuwB43N1bopYtAx4Mjh2kA79190dHIvCBzJ1cyJ9WbKa5o5v8rHiqJiKSeobMju7+PGBxlLsduL3ftHXAEXsY27DNLS8E4PW6XVTOGL+/XlZEZExJqjt355UXAai5R0RkEEmV+MsKsxifl8nKTUr8IiKxJFXiNzPmTtYFXhGRwSRV4oegZ88b9U109fQmOhQRkVEp6RL/3PJCOrt7eauhOdGhiIiMSsmX+CcHPXtW1aq5R0RkIEmX+A8sySc7I02JX0QkhqRL/JE0Y86kQlYq8YuIDCjpEj/wbs8ed090KCIio05SJv555YXsbOuidmd7okMRERl1kjLx9w3dsHLTzgRHIiIy+iRl4j94UgFmGrpBRGQgSZn4czPTOXBinnr2iIgMICkTP8Dc8iL17BERGUDyJv7JhWza0cbO1q5EhyIiMqokbeKfF17gVTu/iMj7JW3iPyQcumFlrXr2iIhES9rEX1KQRWlBls74RUT6SdrED0F/fvXsERF5v6RO/PPKC1m7pZmO7p5EhyIiMmokdeKfO7mI7l5nTb3G5hcR6ZPcib9cY/OLiPSX1Il/+vhc8jIj6tkjIhIlqRN/WppxiH58XUTkfYZM/GY21cyeMrNVZrbSzK4ZoMw/mdnS8LHCzHrMbHw470wze8PM1prZ1/ZFJQYzt7yQ1XVN9PZqbH4REYjvjL8buM7d5wLHAl80s7nRBdz9++5+pLsfCXwdeMbdG80sAvwUOAuYC1zaf9l9bV55Ic0d3WxobN2fLysiMmoNmfjdvc7dl4TPm4DVwJRBFrkUuCt8vhBY6+7r3L0TuBs4f+9CHp65k4sADd0gItJnWG38ZjYDmA8sjjE/FzgTeCCcNAXYGFWkhhgHDTO70syqzKyqoaFhOGENalZZPpE0U88eEZFQ3InfzPIJEvq17h4ri54HvODujcMNxN1vdfdKd68sKSkZ7uIxZWdEmFWar549IiKhuBK/mWUQJP073X3RIEUv4b1mHoBNwNSo/yvCafvVXPXsERF5Vzy9egz4JbDa3W8YpFwRcDLw+6jJrwCzzOwAM8skODA8tHchD9/c8kLqd3Wwtbljf7+0iMiokx5HmeOBy4HlZrY0nPYNYBqAu98cTrsAeNzdW/oWdPduM7saeAyIALe5+8qRCj5e0XfwnjR75JqRRETGoiETv7s/D1gc5W4Hbh9g+iPAI3sQ24iZO/m9H2VR4heRVJfUd+72Kc7NZEpxjnr2iIiQIokfguYe9ewREUmlxD+5kHVbW2jt7E50KCIiCZU6ib+8EHd4Y3NTokMREUmolEn888r7fnxd7fwiktpSJvFPKc6hMDtdN3KJSMpLmcRvZvrxdRERUijxA8wrL+L1zbvo0dj8IpLCUirxz51cSHtXL29v1Y+vi0jqSq3Erwu8IiKplfhnluaTGUnTBV4RSWkplfgzImnMnpSvC7wiktJSKvFDODZ/7S7cdYFXRFJTyiX+eeVFbGvpZEuTxuYXkdSUcon/vQu8GrBNRFJTyiX+gycVAKidX0RSVsol/oLsDGZMyFXPHhFJWSmX+KFvbH4lfhFJTSmZ+OeVF/HOtlbqd7UnOhQRkf0uJRP/WYdOAuDBVzclOBIRkf0vJRP/gSX5VE4fx31VG9WfX0RSTkomfoALF1TwVkMLSzfuSHQoIiL7Vcom/nMOn0x2Rhr3VdckOhQRkf0qZRN/QXYGZx86mYeX1dLe1ZPocERE9pshE7+ZTTWzp8xslZmtNLNrYpQ7xcyWhmWeiZq+3syWh/OqRjL4vXXhggqa2rt5bOXmRIciIrLfpMdRphu4zt2XmFkBUG1mT7j7qr4CZlYM/Aw40903mFlpv3Wc6u5bRy7skXHsgROYUpzD/dU1nH/klESHIyKyXwx5xu/ude6+JHzeBKwG+mfJy4BF7r4hLLdlpAPdF9LSjI8tqOD5tVup3dGW6HBERPaLYbXxm9kMYD6wuN+s2cA4M3vazKrN7FNR8xx4PJx+5SDrvtLMqsysqqGhYThh7ZULj6rAXX36RSR1xJ34zSwfeAC41t37j3eQDiwAzgHOAP7VzGaH805w96OAs4AvmtlJA63f3W9190p3rywpKRluPfbYtAm5HHPAePXpF5GUEVfiN7MMgqR/p7svGqBIDfCYu7eEbfnPAkcAuPum8O8W4EFg4UgEPpI+XjmV9dtaqXpne6JDERHZ5+Lp1WPAL4HV7n5DjGK/B04ws3QzywWOAVabWV54QRgzywM+BKwYmdBHzlmHTiI3M8L9VerTLyLJL54z/uOBy4HTwi6ZS83sbDO7ysyuAnD31cCjwGvAy8Av3H0FUAY8b2bLwul/dPdH90lN9kJeVjrnHDaZP7xWS2tnd6LDERHZp4bszunuzwMWR7nvA9/vN20dYZPPaHfhggruq67h0RWb+ehRFYkOR0Rkn0nZO3f7W3jAeKZPyOU+NfeISJJT4g+ZGRceVcFL67axsbE10eGIiOwzSvxRPrqgAjN4YInO+kUkeSnxR5lSnMPxB03kgSU19PaqT7+IJCcl/n4uXFDBxsY2Fr/dmOhQRET2CSX+fs6YN4mCrHTu1zj9IpKklPj7ycmMcO4Rk3lkeR3NHerTLyLJR4l/ABcumEpbVw+PLK9LdCgiIiNOiX8AR00r5sCSPA3hICJJSYl/AGbGhQsqeHl9I+u3tiQ6HBGREaXEH8NH51eQpj79IpKElPhjmFSUzYmzSniguoYe9ekXkSSixD+Ij1dWULuznRffGnU/FywisseU+AfxwUPKmJCXyXf/uJq2zp5EhyMiMiKU+AeRnRHhhouP5I36Jv7fg8v104wikhSU+Idw8uwSrv2b2Sx6dRN3Lt6Q6HBERPaaEn8c/uG0mZwyp4RvP7yKpRt3JDocEZG9osQfh7Q040cXH0lpYRZ//5tqGls6Ex2SiMgeU+KPU3FuJjd/cgFbWzr50l2vqouniIxZSvzDcOiUIr5z/jyeX7uVH/35zUSHIyKyR5T4h+nio6dxUWUFNz65lr+srk90OCIiw6bEvwe+ff6hzCsv5Mv3LGXDNv0+r4iMLUr8eyA7I8LNn1wAwFW/qaa9Szd3icjYMWTiN7OpZvaUma0ys5Vmdk2McqeY2dKwzDNR0880szfMbK2ZfW0kg0+kqeNz+dElR7Kqbhf/8rsVurlLRMaMeM74u4Hr3H0ucCzwRTObG13AzIqBnwEfdvd5wMfD6RHgp8BZwFzg0v7LjmWnHVzGl06byf3VNdz9ysZEhyMiEpchE7+717n7kvB5E7AamNKv2GXAInffEJbbEk5fCKx193Xu3gncDZw/UsGPBtd8cDYnzprIN3+/ktdqdHOXiIx+w2rjN7MZwHxgcb9Zs4FxZva0mVWb2afC6VOA6FPhGnY/aIxpkTTjx5fMp6Qgi6t+Xc3GRl3sFZHRLe7Eb2b5wAPAte6+q9/sdGABcA5wBvCvZjZ7OIGY2ZVmVmVmVQ0NDcNZNOHG52Vyy+ULaOns4eM3v8TaLc2JDklEJKa4Er+ZZRAk/TvdfdEARWqAx9y9xd23As8CRwCbgKlR5SrCabtx91vdvdLdK0tKSoZTh1Hh0ClF3PP5Y+nudS665SVWbNqZ6JBERAYUT68eA34JrHb3G2IU+z1wgpmlm1kucAzBtYBXgFlmdoCZZQKXAA+NTOijz8GTCrnvquPIyYhw6c//StX6xkSHJCKym3jO+I8HLgdOC7trLjWzs83sKjO7CsDdVwOPAq8BLwO/cPcV7t4NXA08RnAguNfdV+6TmowSB0zM496rjmNifhaX//JlnlsztpqtRCT52Wjsf15ZWelVVVWJDmOvNDR1cPkvF7OuoYWbLpvPh+ZNSnRIIpLEzKza3SvjKas7d/eRkoIs7r7yWOaWF/KFO5fwu1cHvLQhIrLfKfHvQ8W5mfzmc8ewcMZ4vnzvUu5c/E6iQxIRUeLf1/Kz0vm/K47m1Dml/L8HV3DLM28lOiQRSXFK/PtB36Bu5xw+mf/80+v84PE3NLaPiCRMeqIDSBWZ6Wn85JL55Gemc+OTa+no7uXrZx1M0FtWRGT/UeLfjyJpxvc+dhiZ6Wnc+uw6cjIifPn0Yd3gLCKy15T49zMz41sfnkdbVw8//ssacjIjXHXyQYkOS0RSiBJ/AqSlGf/1scNp7+rhe396nZyMCJ/+wIxEhyUiKUKJP0EiacYPLz6Sju5evvnQSnIyIlx09NShFxQR2Uvq1ZNAGZE0brpsPifOmshXF73GQ8tqEx2SiKQAJf4Ey0qPcOvllRw9Yzxfvmcpj6/cnOiQRCTJKfGPAjmZEW77zNEcOqWIq3/7Ks+8qYHdRGTfUeIfJfKz0rnjioXMLM3nyjuq+Ou6bYkOSUSSlBL/KFKUm8GvP7uQqeNz+eztr7Bkw/ZEhyQiSUiJf5SZkJ/FnZ87hokFWXzmtpdZWatf8hKRkaXEPwqVFWZz5+eOIT8rnY/+7EUuufUlbnj8DZ59s4Hmju5EhyciY5z68Y9SFeNyuefzx3HbC29TtX47Nz21ll6HNIO55YVUTh/PwgPGUzljHKUF2YkOV0TGEP0C1xjR3NHNqxu288rbjbyyfjuvbtxOe1cvADMm5FI5Yzynzy3j1DmlZKbri5xIqhnOL3DpjH+MyM9K58RZJZw4qwSArp5eVmzaSdX67by8vpE/r67n/uoaxudl8pEjp3DhggrmlhcmOGoRGY10xp8kunt6eXZNA/dX1/DnVVvo7Oll7uRCLlxQwflHljMhPyvRIYrIPjScM34l/iS0vaWTh5bVcn91Dcs37SQjYpx2cCkXLpjKKXNKyIioKUgk2Sjxy7te37yLB6prePDVTWxt7mRCXiYXVlbw9yfPpCg3I9HhicgIUeKX3XT19PLMGw3cV72RJ1bVU5ybyT+fMYeLKqeSlqZfARMZ64aT+PWdP0VkRNL44Nwybrm8kof/4QQOKsnja4uWc8HPXuBV3SEsklKGTPxmNtXMnjKzVWa20syuGaDMKWa208yWho9/i5q33syWh9N1Gj8KzCsv4t7PH8ePLj6Sup3tXPCzF/mn+5bR0NSR6NBEZD+IpztnN3Cduy8xswKg2syecPdV/co95+7nxljHqe6+da8ilRFlZnxk/hQ+OLeMG59cw23Pv82jKzZz7emz+dRx03UBWCSJDfnpdvc6d18SPm8CVgNT9nVgsn/kZ6Xz9bMO4dFrT+Ko6eP4zh9Wcc5PnuPFtTpOiySrYZ3WmdkMYD6weIDZx5nZMjP7k5nNi5ruwONmVm1mVw6y7ivNrMrMqhoaNB79/nZQST63X3E0P/9UJW1dPVz2i8X8/Z3VrKrdxWjsACAiey7uXj1mlg88A3zX3Rf1m1cI9Lp7s5mdDfzY3WeF86a4+yYzKwWeAP7B3Z8d7LXUqyex2rt6uPXZdfzs6bW0d/UyszSfDx9RznlHlHPAxLxEhyciAxjx7pxmlgH8AXjM3W+Io/x6oLJ/u76ZXQ80u/v/DLa8Ev/osK25gz+t2MxDy2p5ZX0j7nDolEI+fEQ55x5eTnlxTqJDFJHQiCZ+MzPgV0Cju18bo8wkoN7d3cwWAvcD04FcIM3dm8wsj+CM/9vu/uhgr6nEP/rU7Wzjj6/V8dCyWl6rCX4j4OgZ4/jwEeWcddhkJmpICJGEGunEfwLwHLAc6A0nfwOYBuDuN5vZ1cAXCHoAtQFfcfcXzexA4MFwmXTgt+7+3aGCUuIf3dZvbeEPr9Xy0LJa3qxvJpJmnDK7hH88Yw6HTNbAcCKJoDt3Zb95Y3MTDy3bxJ2LN7CrrYuLj57KV06fQ0mBvgGI7E9K/LLf7Wzt4sd/WcMdL60nOyPCF0+dyRXHzyA7I5Lo0ERSgoZskP2uKDeDfztvLo9/+SSOPXA8//Xo65z+w2d4ZHmduoOKjDJK/DKiDizJ5xefPpo7P3cMeZnp/P2dS7j4lr/yWs2ORIcmIiElftknjp85kT9+6UT+44LDeKuhmQ/f9AJfuXcpm3e2Jzo0kZSnNn7Z53a1d/HTp9byf8+vJ5JmzC7LJyOSFjzS08iMpJGZbu9Ni6SRlZ7GpKJsLl04jaIc/W6AyFB0cVdGpQ3bWvnZ02vZvKudzu5eunp66exxut593ktXdzitp5edbV0UZqfz+ZMP4orjZ5CbqZ+IFolFiV+Swsranfzg8Td58vUtTMzP4ounHsRlx0wjK109hUT6U+KXpFL9TiPff+wN/rqukSnFOXzpb2bysaMqSNfQ0SLvUndOSSoLpo/nrr87lt989hgm5mfy1QeW86EfPstDy2rp7R19Jy4io50Sv4wJZsYJsybyuy8ez62XLyAjksaX7nqVs3/yHH9eVa8DgMgwqKlHxqTeXucw15DcAAAMMklEQVTh12r54RNvsn5bKzkZEWaX5TO7rCB4TCpgTlkBZYVZBOMMiiQ3tfFLyujq6eWR5XUs3biDNfXNvFHf9L7fDi7MTn/fgeDQKUXMn1pMWpoOBpJclPglpTW2dPJmfdN7j83BAWFnWxcAkwqzOfuwyZx3xGSOnFqsbwSSFJT4Rfpxd7Y0dfDXddt4eFkdz77ZQGdPLxXjcjjn8Mmcd3g588oLdRCQMUuJX2QIO9u6eGJVPQ8vq+WFtVvp7nUOmJjHuYdP5tzDy5kzqSDRIYoMixK/yDBsb+nk0ZWbeXhZLX9dt41eh1ml+cyYmEdmehpZkbTgb3rwNzM9jcxIhKyMYLiJCfmZHHfQBEoLshNdFUlhw0n8ugdeUt64vEwuXTiNSxdOY0tTO4+u2MzjK+vZ2NhKZ08vnd29dHQHf4PnPQzUe/TgSQWcNLuEE2dN5OgZ4/VbBDJq6YxfZA90h2MLdXb3UrO9jefWbOW5NQ1Urd9OZ08vWelpLDxgPCfNKuHE2ROZU1ag6weyT6mpRyRBWju7Wfx2I8+9GRwI1mxpBqCkIIsTZ03kvMPLOWl2CRF1J5URpqYekQTJzUzn1DmlnDqnFIC6nW08v2Yrz63ZylOvb2HRkk2UF2Vz0dFTuahyKuXFOQmOWFKRzvhF9pPO7l7+srqeu17ZyHNrGjDg1DmlXLpwGqfMKdGgc7JX1NQjMsptbGzlnlc2ck/VRhqaOigrzOLiyqlcdPRUKsblJjo8GYOU+EXGiK6eXp58fQt3vbyBZ95sAODk2SWcdegkCrMzyM4Iuo1mZ0TIyYiQnREhOyON7PQIOZkRstLTdNFYALXxi4wZGZE0zpg3iTPmTaJmeyv3VtVw7ysbefqNhriWN4MpxTnMLitgVmk+s8oKmF2Wz8zSfP1imcQ05Bm/mU0F7gDKAAdudfcf9ytzCvB74O1w0iJ3/3Y470zgx0AE+IW7f2+ooHTGL6msu6eXTTvaaOvqob2rl7bOHtq7e+jo+7+rh/bweWtnN+u3tbKmvol1DS109vQCwQGhYlwOs0oLmFWWz+zSAmZMzKMkP4vx+ZnkZUb0TSHJjPQZfzdwnbsvMbMCoNrMnnD3Vf3KPefu5/YLJAL8FDgdqAFeMbOHBlhWRELpkTSmT8gb9nLdPb3vHgTerG9mzZYm1tQ389yaBrp63n+Cl5mexoS8TCbkZzI+L4sJeZmMDx8T8zM5dEoRh0wq1CimSWrIxO/udUBd+LzJzFYDU4B4kvdCYK27rwMws7uB8+NcVkSGIT2SxszSoJnnrMPem97V08s721rY0NjKtuZOGls62dbSGT7voLGlk3UNzTS2dNLa2fPucsW5GRx7wAQ+MHMCHzhoAgeV5OtbQpIYViOgmc0A5gOLB5h9nJktA2qBf3T3lQQHiI1RZWqAY2Ks+0rgSoBp06YNJywRGURGJI2ZpQXMLB164Ln2rh7qd7WzZMN2Xly7jRff2sajKzcDwU1oxx0YHASOO2gC08bnxjwQdPf00tLRQ1NHFy0dPbR2djOzNJ+C7IwRrZvsmbgTv5nlAw8A17r7rn6zlwDT3b3ZzM4GfgfMGk4g7n4rcCsEbfzDWVZERkZ2RoTpE/KYPiGPC+ZX4O5sbGzjpXVbefGt4EDw0LJaoO+icj5tXT00d3TT3N5Nc0cPzR1dtHf17rbujIhx9IzxnHZwKafMKeWgkjx9g0iQuLpzmlkG8AfgMXe/IY7y64FKguR/vbufEU7/OoC7/+dgy+virsjo5O681dDCS29t5aV121i/tZX87HTys4JHXlY6BdlRz8O/GRGjesN2nnp9C2/WB8NYTBufy2kHl3LqwaUcc4AGtdtbI9qP34JD8q+ARne/NkaZSUC9u7uZLQTuB6YT9OR5E/gbYBPwCnBZ2AwUkxK/SPKq2d7KU2808NTrW3jxra20d/WSkxHh+JkTOPXgUo6eMT44cGSmk5sVIUN3NMdlpHv1HA9cDiw3s6XhtG8A0wDc/WbgQuALZtYNtAGXeHBE6Tazq4HHCA4Ctw2V9EUkuVWMy+XyY6dz+bHTae/q4aV123jq9S08+foW/rx6y27lMyNp5GZFyMtMJyczQl5mhNzMdPKyIhTmZFCck0lxbkb4yKQ4J3yek0lRbgaF2elqUupHd+6KyKjg7qzd0syqul20dvYEj45uWjqDi8MtHT20dXW/e7G4uaOHXW1d7GjtpCWqN1J/kTRjfF4mFeNyqBiXS8W4HKaGfyvG5VBenDNkM5O709IZvN6u9i52tnbhwOSibCYVZZOVnvhmKt25KyJjjpkxq6yAWWXD/9nLzu5edrZ1sbOtk+2tXexoDQ4IO9u62N7aSUNTBzXb21i2cQd/Wl5Hd79f0ikrzKJiXC7lxTl09/Syq72LXW3dQZJv66KpvZuegX59JzQxP5PJRTlMLsqmvDj4O7k4h/Lwb1lB1qgahE+JX0TGvMz0NEoKsigpyBqybE+vs3lXOzWNrdRsb6Nmexsbt7dSs72VZRt3kJmeRmF2OhPzMzmwJI/C7AyKcjIozEmnMDuDwpzgf/dg2O26ne3U7Wyjdkc767e18NJb22jq6H7fa0bSjEmF2UwpzqG8OJsp43KYUpxLeXH2u9869ucQG0r8IpJSImnGlOIcphTnDHxT0Qhoau+ibmc7tTva3v27aXsbNTvaqHpnOw+/VrfbN4hxuRnMLM3nvqs+sI+ieo8Sv4jICCvIzqAgO4PZMZqtenqd+l3tbNrRRu2O4FvHph1t9A7SnDSSlPhFRPazSJpRXpyTsF9gGz1XG0REZL9Q4hcRSTFK/CIiKUaJX0QkxSjxi4ikGCV+EZEUo8QvIpJilPhFRFLMqByd08wagHf2cPGJwNYRDCfRkq0+kHx1Srb6QPLVKdnqA7vXabq7l8Sz4KhM/HvDzKriHZp0LEi2+kDy1SnZ6gPJV6dkqw/sXZ3U1CMikmKU+EVEUkwyJv5bEx3ACEu2+kDy1SnZ6gPJV6dkqw/sRZ2Sro1fREQGl4xn/CIiMgglfhGRFJM0id/MzjSzN8xsrZl9LdHxjAQzW29my81sqZlVJTqePWFmt5nZFjNbETVtvJk9YWZrwr/jEhnjcMSoz/VmtincTkvN7OxExjgcZjbVzJ4ys1VmttLMrgmnj+VtFKtOY3I7mVm2mb1sZsvC+nwrnH6AmS0Oc949ZpYZ9zqToY3fzCLAm8DpQA3wCnCpu69KaGB7yczWA5XuPmZvPDGzk4Bm4A53PzSc9t9Ao7t/LzxIj3P3ryYyznjFqM/1QLO7/08iY9sTZjYZmOzuS8ysAKgGPgJ8hrG7jWLV6SLG4HYyMwPy3L3ZzDKA54FrgK8Ai9z9bjO7GVjm7v8bzzqT5Yx/IbDW3de5eydwN3B+gmMSwN2fBRr7TT4f+FX4/FcEH8oxIUZ9xix3r3P3JeHzJmA1MIWxvY1i1WlM8kBz+G9G+HDgNOD+cPqwtlGyJP4pwMao/2sYwxs6igOPm1m1mV2Z6GBGUJm714XPNwNliQxmhFxtZq+FTUFjplkkmpnNAOYDi0mSbdSvTjBGt5OZRcxsKbAFeAJ4C9jh7t1hkWHlvGRJ/MnqBHc/CjgL+GLYzJBUPGhrHOvtjf8LHAQcCdQBP0hsOMNnZvnAA8C17r4ret5Y3UYD1GnMbid373H3I4EKghaOg/dmfcmS+DcBU6P+rwinjWnuvin8uwV4kGCDJ4P6sB22rz12S4Lj2SvuXh9+MHuBnzPGtlPYbvwAcKe7Lwonj+ltNFCdxvp2AnD3HcBTwHFAsZmlh7OGlfOSJfG/AswKr3JnApcADyU4pr1iZnnhhSnMLA/4ELBi8KXGjIeAT4fPPw38PoGx7LW+BBm6gDG0ncILh78EVrv7DVGzxuw2ilWnsbqdzKzEzIrD5zkEnVhWExwALgyLDWsbJUWvHoCwa9aPgAhwm7t/N8Eh7RUzO5DgLB8gHfjtWKyTmd0FnEIwhGw98E3gd8C9wDSC4bcvcvcxccE0Rn1OIWg+cGA98Pmo9vFRzcxOAJ4DlgO94eRvELSJj9VtFKtOlzIGt5OZHU5w8TZCcLJ+r7t/O8wRdwPjgVeBT7p7R1zrTJbELyIi8UmWph4REYmTEr+ISIpR4hcRSTFK/CIiKUaJX0QkxSjxi4ikGCV+EZEU8/8BVfW0FEG1RgkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_error_plot(m):\n",
    "    (itrs, train_errs, train_bl, test_errs, test_bl) = list(zip(*m.training_process))\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    ax.plot(itrs, train_errs, label=\"training err\")\n",
    "    ax.plot(itrs, train_bl, label=\"baseline\")\n",
    "    ax.set_title(\"Error versus Iteration of SGD for training set\")\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    ax.plot(itrs, test_errs, label=\"training err\")\n",
    "    ax.plot(itrs, test_bl, label=\"baseline\")\n",
    "    ax.set_title(\"Error versus Iteration of SGD for test set\")\n",
    "\n",
    "make_error_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>5.652366</td>\n",
       "      <td>TH71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Score Style\n",
       "3517  5.652366  TH71"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what = model.predict_for_user(\"000966f4-c977-3a9d-8477-8825fa6084bb\")\n",
    "what[what['Style'] == 'TH71']#880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a5938ace3f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>style</th>\n",
       "      <th>didnt_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192388</th>\n",
       "      <td>DVF99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278841</th>\n",
       "      <td>TH71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387385</th>\n",
       "      <td>JWG2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542576</th>\n",
       "      <td>KPL26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549090</th>\n",
       "      <td>ER13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563807</th>\n",
       "      <td>CVN51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615533</th>\n",
       "      <td>DRW2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653059</th>\n",
       "      <td>MRR5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695615</th>\n",
       "      <td>CAS62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731063</th>\n",
       "      <td>RL4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733408</th>\n",
       "      <td>TB227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747279</th>\n",
       "      <td>ZDV11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753313</th>\n",
       "      <td>EVD3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764997</th>\n",
       "      <td>RM85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768872</th>\n",
       "      <td>TYB69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905093</th>\n",
       "      <td>DL89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111476</th>\n",
       "      <td>CAE35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114416</th>\n",
       "      <td>DRW3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         style  didnt_fit\n",
       "192388   DVF99          0\n",
       "278841    TH71          1\n",
       "387385    JWG2          0\n",
       "542576   KPL26          0\n",
       "549090    ER13          0\n",
       "563807   CVN51          0\n",
       "615533    DRW2          0\n",
       "653059    MRR5          0\n",
       "695615   CAS62          0\n",
       "731063     RL4          0\n",
       "733408   TB227          0\n",
       "747279   ZDV11          0\n",
       "753313    EVD3          0\n",
       "764997    RM85          0\n",
       "768872   TYB69          0\n",
       "905093    DL89          0\n",
       "1111476  CAE35          0\n",
       "1114416   DRW3          0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#user_reviews = user_reviews.set_index('order_id')\n",
    "#user_reviews.join(user_orders, how='left', on='')\n",
    "#user_orders = user_orders.set_index('order_id')\n",
    "#user_orders.join(reviews, how=\"left\")\n",
    "\n",
    "#orders.loc['order_id' == \"9f965f2a-b0e3-3d26-87b7-127d9d4a2e50\"]\n",
    "#orders[orders['user_id'] == \"0001b9a8-0a05-3677-9e1d-7fc05a9a9b67\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ordered_date</th>\n",
       "      <th>rental_begin_date</th>\n",
       "      <th>style</th>\n",
       "      <th>sku</th>\n",
       "      <th>days_rented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97471</th>\n",
       "      <td>36673766-3005-3700-af31-097ca5a66822</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>ASR10</td>\n",
       "      <td>ASR10_M</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853625</th>\n",
       "      <td>a1e67167-089f-3855-852d-0fe5e1c956f4</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>DRW13</td>\n",
       "      <td>DRW13_M</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253129</th>\n",
       "      <td>f4d174b7-f87a-35a1-98a6-688d2423e4ee</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>TNT24</td>\n",
       "      <td>TNT24_8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151198</th>\n",
       "      <td>7e87505b-fd7a-3b65-b8cd-e5bb9af660ba</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>PK213</td>\n",
       "      <td>PK213_M</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211566</th>\n",
       "      <td>c152f63c-55e4-3e56-bee7-a45692ea6ccb</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>SHL2</td>\n",
       "      <td>SHL2_M</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160524</th>\n",
       "      <td>bf9796cc-3ae1-36a5-87c0-89e17a3cfdc5</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>CUP18</td>\n",
       "      <td>CUP18_M</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201341</th>\n",
       "      <td>f5f88fdd-6c56-3b34-817f-d81c9830be1b</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>CED42</td>\n",
       "      <td>CED42_44</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648411</th>\n",
       "      <td>fe599875-0a1d-3825-a1b6-3aebdd2210a9</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>BSH10</td>\n",
       "      <td>BSH10_2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351339</th>\n",
       "      <td>085e7f72-191e-39e0-8d16-ba85f7f43595</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>JWG28</td>\n",
       "      <td>JWG28_10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891703</th>\n",
       "      <td>fcbdc570-c061-3dd6-946d-b7f71af91919</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>DL104</td>\n",
       "      <td>DL104_L</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740478</th>\n",
       "      <td>e2829051-a06e-3fb5-a560-c5151abc8d29</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>BM497</td>\n",
       "      <td>BM497_8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671079</th>\n",
       "      <td>29ac16e9-dca4-3164-9998-9517c72b1f4d</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>AMU87</td>\n",
       "      <td>AMU87_M</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538604</th>\n",
       "      <td>b2db6274-8c89-3729-b107-84c5975a2fbb</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>WVG52</td>\n",
       "      <td>WVG52_M</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757634</th>\n",
       "      <td>54f42c54-08b8-36cd-b147-c9de516ab122</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>EQ63</td>\n",
       "      <td>EQ63_L</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595894</th>\n",
       "      <td>037f8aaf-df47-3d79-90f1-1cb03f373f43</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>DL79</td>\n",
       "      <td>DL79_8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756896</th>\n",
       "      <td>17d836a6-37b2-3198-8bcc-3f9b9e9509a3</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>PPC32</td>\n",
       "      <td>PPC32_M</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233756</th>\n",
       "      <td>70d681a7-239f-3a8b-a5fd-fe0d9c8d312d</td>\n",
       "      <td>0001b9a8-0a05-3677-9e1d-7fc05a9a9b67</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>SB39</td>\n",
       "      <td>SB39_40</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901500</th>\n",
       "      <td>8dbba08f-a5e4-362a-846d-22772fd9735e</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>ASR8</td>\n",
       "      <td>ASR8_S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828656</th>\n",
       "      <td>7a6c314b-f13c-30cd-8187-63a0090da56d</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>DVF188</td>\n",
       "      <td>DVF188_XS</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681417</th>\n",
       "      <td>f6263f2e-107e-3b58-87a8-de68f7a2bbf2</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>KPL27</td>\n",
       "      <td>KPL27_S</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680314</th>\n",
       "      <td>5d78632d-1e6e-3329-b520-f053a83d2ce2</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>WVG53</td>\n",
       "      <td>WVG53_XS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784437</th>\n",
       "      <td>cf04e322-1f89-31bc-aeb4-05dca3283938</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>FZ16</td>\n",
       "      <td>FZ16_XS</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602499</th>\n",
       "      <td>c2c02a0b-46cc-3e66-8d78-88e3b8f2d4f6</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>BRA5</td>\n",
       "      <td>BRA5_XS</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674034</th>\n",
       "      <td>03b5d119-2512-301a-bac3-2e0abd41ecf1</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>DRW4</td>\n",
       "      <td>DRW4_XS</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356137</th>\n",
       "      <td>0990979c-8d1e-3e00-9b8d-f9fb5e656329</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>JWG19</td>\n",
       "      <td>JWG19_XS</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598892</th>\n",
       "      <td>ef1edc67-98df-3b9b-8bec-32536829162b</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>MRR3</td>\n",
       "      <td>MRR3_XS</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170765</th>\n",
       "      <td>29be0752-e479-3fdb-8fd3-0b21236874da</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>ZDV16</td>\n",
       "      <td>ZDV16_XS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743433</th>\n",
       "      <td>ffe0ca1f-f806-319f-ab7c-1edc2dd18aa4</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>ML216</td>\n",
       "      <td>ML216_XS</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823384</th>\n",
       "      <td>a79e85d4-b1b5-342d-9377-227eb5775457</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2018-02-14</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>FNP23</td>\n",
       "      <td>FNP23_2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649449</th>\n",
       "      <td>235b68f2-1db2-3d79-bae7-09978cd52fb7</td>\n",
       "      <td>00020785-d3b3-3ffd-9d1a-4be3539a260a</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>WVG64</td>\n",
       "      <td>WVG64_S</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645222</th>\n",
       "      <td>10ec01e2-6fd0-343b-87d5-9ccfceb5869b</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>JE67</td>\n",
       "      <td>JE67_S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555746</th>\n",
       "      <td>21689ea0-fd44-3e6f-b02d-178011fe0e55</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>CUP10</td>\n",
       "      <td>CUP10_S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544288</th>\n",
       "      <td>530d8736-1175-3a4d-9842-aa9a7fb57d74</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>DVF123</td>\n",
       "      <td>DVF123_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229462</th>\n",
       "      <td>dbdca90e-9f21-3931-875c-b58fc67fb4ea</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-10-15</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>CVN58</td>\n",
       "      <td>CVN58_36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473283</th>\n",
       "      <td>c443e810-3177-33df-aeb7-ee61223814d5</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-03-24</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>TH88</td>\n",
       "      <td>TH88_2R</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229399</th>\n",
       "      <td>fe38a6e8-ce13-3e5b-b2c8-5f0f2b1d57ad</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>TT150</td>\n",
       "      <td>TT150_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493185</th>\n",
       "      <td>14ab92c3-50e7-3a6f-8140-fd4825550abd</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>RZ54</td>\n",
       "      <td>RZ54_2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117866</th>\n",
       "      <td>fdd6d374-0a95-3c59-aa9f-60e08d866ce5</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-10-22</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>RT115</td>\n",
       "      <td>RT115_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082042</th>\n",
       "      <td>0631d830-a722-38eb-9152-48e51b138876</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>DAG1</td>\n",
       "      <td>DAG1_XS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644244</th>\n",
       "      <td>7503c8ad-4305-3569-8b72-85a3db1b8ac5</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>NM297</td>\n",
       "      <td>NM297_S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111354</th>\n",
       "      <td>aea71e73-2804-3ee7-9d2a-d87684429288</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>RV8</td>\n",
       "      <td>RV8_2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90860</th>\n",
       "      <td>8e12957a-ad53-3989-a985-2ee0dd73587b</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-09-25</td>\n",
       "      <td>2017-09-27</td>\n",
       "      <td>AMU55</td>\n",
       "      <td>AMU55_XSR</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239097</th>\n",
       "      <td>6512134e-108c-3c65-baa2-bcd13ce2f8f7</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>TLA9</td>\n",
       "      <td>TLA9_S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084897</th>\n",
       "      <td>36d54012-02d5-3338-98a3-121343511e9e</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>AMU71</td>\n",
       "      <td>AMU71_S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373818</th>\n",
       "      <td>3114ff41-d21d-36f5-a268-ed3157a48198</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>RT107</td>\n",
       "      <td>RT107_2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658278</th>\n",
       "      <td>f6dc071a-1184-3679-9f3c-9c667181c0db</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>BBC2</td>\n",
       "      <td>BBC2_XS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592274</th>\n",
       "      <td>6298ee05-52a8-3cd5-bd1a-e53019109a65</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>LVF7</td>\n",
       "      <td>LVF7_S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331747</th>\n",
       "      <td>c6c92dd6-1d93-3275-af47-8dd9fbddfd1f</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>FP66</td>\n",
       "      <td>FP66_S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127807</th>\n",
       "      <td>b15e5450-ddba-3412-9f1b-8fcf634ce064</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>BBC3</td>\n",
       "      <td>BBC3_XS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126213</th>\n",
       "      <td>70d47dbe-8022-3bd8-ad83-f841150770cf</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>PTS7</td>\n",
       "      <td>PTS7_XS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174615</th>\n",
       "      <td>2c4722aa-c45d-3a61-9a8c-5b8e3717d50c</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>JOA35</td>\n",
       "      <td>JOA35_S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698548</th>\n",
       "      <td>fd4356d5-b2b0-3da6-98ca-df872d06bb11</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>TMO9</td>\n",
       "      <td>TMO9_S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97689</th>\n",
       "      <td>2237a70c-ee84-3211-8239-ab7a844648da</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>PK174</td>\n",
       "      <td>PK174_0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094573</th>\n",
       "      <td>d4932e32-328b-3535-ae26-a51314704e7a</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>MST14</td>\n",
       "      <td>MST14_S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527526</th>\n",
       "      <td>f20febd0-f393-32ae-897f-a37c69ce2c58</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>CUP11</td>\n",
       "      <td>CUP11_XS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460644</th>\n",
       "      <td>368851f4-b049-3517-b8b1-6a4be3a5bda8</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>BM470</td>\n",
       "      <td>BM470_2R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136145</th>\n",
       "      <td>5d5267e0-500f-3962-85a6-463c79dc8073</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-10-22</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>EF184</td>\n",
       "      <td>EF184_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866111</th>\n",
       "      <td>9afa3af4-cc11-3a8e-9555-cdb8cff66148</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2018-03-03</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>AJY11</td>\n",
       "      <td>AJY11_S</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760959</th>\n",
       "      <td>ffd1cefd-b4a6-399e-9878-62ac24fd89d5</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>DVN3</td>\n",
       "      <td>DVN3_S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425827</th>\n",
       "      <td>992b5ba5-1395-3e51-83fb-5026d71502e7</td>\n",
       "      <td>fffbf904-08c2-3096-ba13-619e749c3900</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>TB198</td>\n",
       "      <td>TB198_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228395 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     order_id  \\\n",
       "97471    36673766-3005-3700-af31-097ca5a66822   \n",
       "853625   a1e67167-089f-3855-852d-0fe5e1c956f4   \n",
       "253129   f4d174b7-f87a-35a1-98a6-688d2423e4ee   \n",
       "1151198  7e87505b-fd7a-3b65-b8cd-e5bb9af660ba   \n",
       "1211566  c152f63c-55e4-3e56-bee7-a45692ea6ccb   \n",
       "1160524  bf9796cc-3ae1-36a5-87c0-89e17a3cfdc5   \n",
       "1201341  f5f88fdd-6c56-3b34-817f-d81c9830be1b   \n",
       "648411   fe599875-0a1d-3825-a1b6-3aebdd2210a9   \n",
       "351339   085e7f72-191e-39e0-8d16-ba85f7f43595   \n",
       "891703   fcbdc570-c061-3dd6-946d-b7f71af91919   \n",
       "740478   e2829051-a06e-3fb5-a560-c5151abc8d29   \n",
       "671079   29ac16e9-dca4-3164-9998-9517c72b1f4d   \n",
       "538604   b2db6274-8c89-3729-b107-84c5975a2fbb   \n",
       "757634   54f42c54-08b8-36cd-b147-c9de516ab122   \n",
       "595894   037f8aaf-df47-3d79-90f1-1cb03f373f43   \n",
       "756896   17d836a6-37b2-3198-8bcc-3f9b9e9509a3   \n",
       "233756   70d681a7-239f-3a8b-a5fd-fe0d9c8d312d   \n",
       "901500   8dbba08f-a5e4-362a-846d-22772fd9735e   \n",
       "828656   7a6c314b-f13c-30cd-8187-63a0090da56d   \n",
       "681417   f6263f2e-107e-3b58-87a8-de68f7a2bbf2   \n",
       "680314   5d78632d-1e6e-3329-b520-f053a83d2ce2   \n",
       "784437   cf04e322-1f89-31bc-aeb4-05dca3283938   \n",
       "602499   c2c02a0b-46cc-3e66-8d78-88e3b8f2d4f6   \n",
       "674034   03b5d119-2512-301a-bac3-2e0abd41ecf1   \n",
       "356137   0990979c-8d1e-3e00-9b8d-f9fb5e656329   \n",
       "598892   ef1edc67-98df-3b9b-8bec-32536829162b   \n",
       "1170765  29be0752-e479-3fdb-8fd3-0b21236874da   \n",
       "743433   ffe0ca1f-f806-319f-ab7c-1edc2dd18aa4   \n",
       "823384   a79e85d4-b1b5-342d-9377-227eb5775457   \n",
       "649449   235b68f2-1db2-3d79-bae7-09978cd52fb7   \n",
       "...                                       ...   \n",
       "645222   10ec01e2-6fd0-343b-87d5-9ccfceb5869b   \n",
       "555746   21689ea0-fd44-3e6f-b02d-178011fe0e55   \n",
       "544288   530d8736-1175-3a4d-9842-aa9a7fb57d74   \n",
       "229462   dbdca90e-9f21-3931-875c-b58fc67fb4ea   \n",
       "473283   c443e810-3177-33df-aeb7-ee61223814d5   \n",
       "229399   fe38a6e8-ce13-3e5b-b2c8-5f0f2b1d57ad   \n",
       "493185   14ab92c3-50e7-3a6f-8140-fd4825550abd   \n",
       "117866   fdd6d374-0a95-3c59-aa9f-60e08d866ce5   \n",
       "1082042  0631d830-a722-38eb-9152-48e51b138876   \n",
       "644244   7503c8ad-4305-3569-8b72-85a3db1b8ac5   \n",
       "1111354  aea71e73-2804-3ee7-9d2a-d87684429288   \n",
       "90860    8e12957a-ad53-3989-a985-2ee0dd73587b   \n",
       "239097   6512134e-108c-3c65-baa2-bcd13ce2f8f7   \n",
       "1084897  36d54012-02d5-3338-98a3-121343511e9e   \n",
       "373818   3114ff41-d21d-36f5-a268-ed3157a48198   \n",
       "658278   f6dc071a-1184-3679-9f3c-9c667181c0db   \n",
       "592274   6298ee05-52a8-3cd5-bd1a-e53019109a65   \n",
       "331747   c6c92dd6-1d93-3275-af47-8dd9fbddfd1f   \n",
       "1127807  b15e5450-ddba-3412-9f1b-8fcf634ce064   \n",
       "1126213  70d47dbe-8022-3bd8-ad83-f841150770cf   \n",
       "1174615  2c4722aa-c45d-3a61-9a8c-5b8e3717d50c   \n",
       "698548   fd4356d5-b2b0-3da6-98ca-df872d06bb11   \n",
       "97689    2237a70c-ee84-3211-8239-ab7a844648da   \n",
       "1094573  d4932e32-328b-3535-ae26-a51314704e7a   \n",
       "527526   f20febd0-f393-32ae-897f-a37c69ce2c58   \n",
       "460644   368851f4-b049-3517-b8b1-6a4be3a5bda8   \n",
       "136145   5d5267e0-500f-3962-85a6-463c79dc8073   \n",
       "866111   9afa3af4-cc11-3a8e-9555-cdb8cff66148   \n",
       "760959   ffd1cefd-b4a6-399e-9878-62ac24fd89d5   \n",
       "425827   992b5ba5-1395-3e51-83fb-5026d71502e7   \n",
       "\n",
       "                                      user_id ordered_date rental_begin_date  \\\n",
       "97471    0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-14        2017-12-18   \n",
       "853625   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2018-02-08        2018-02-12   \n",
       "253129   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-14        2017-12-18   \n",
       "1151198  0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-28        2018-01-03   \n",
       "1211566  0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-28        2018-01-03   \n",
       "1160524  0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-28        2018-01-03   \n",
       "1201341  0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-28        2018-01-03   \n",
       "648411   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-14        2017-12-18   \n",
       "351339   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-12-14        2017-12-18   \n",
       "891703   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2018-01-23        2018-01-29   \n",
       "740478   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2018-01-11        2018-01-15   \n",
       "671079   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-11-23        2017-11-28   \n",
       "538604   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-11-23        2017-11-28   \n",
       "757634   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-11-23        2017-11-28   \n",
       "595894   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2018-02-08        2018-02-12   \n",
       "756896   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2017-11-23        2017-11-28   \n",
       "233756   0001b9a8-0a05-3677-9e1d-7fc05a9a9b67   2018-02-08        2018-02-12   \n",
       "901500   00020785-d3b3-3ffd-9d1a-4be3539a260a   2017-11-08        2017-11-09   \n",
       "828656   00020785-d3b3-3ffd-9d1a-4be3539a260a   2018-02-02        2018-02-06   \n",
       "681417   00020785-d3b3-3ffd-9d1a-4be3539a260a   2017-11-08        2017-11-10   \n",
       "680314   00020785-d3b3-3ffd-9d1a-4be3539a260a   2017-11-08        2017-11-10   \n",
       "784437   00020785-d3b3-3ffd-9d1a-4be3539a260a   2018-01-05        2018-01-09   \n",
       "602499   00020785-d3b3-3ffd-9d1a-4be3539a260a   2017-11-25        2017-11-29   \n",
       "674034   00020785-d3b3-3ffd-9d1a-4be3539a260a   2018-01-28        2018-01-30   \n",
       "356137   00020785-d3b3-3ffd-9d1a-4be3539a260a   2018-01-05        2018-01-09   \n",
       "598892   00020785-d3b3-3ffd-9d1a-4be3539a260a   2018-01-05        2018-01-09   \n",
       "1170765  00020785-d3b3-3ffd-9d1a-4be3539a260a   2018-01-19        2018-01-23   \n",
       "743433   00020785-d3b3-3ffd-9d1a-4be3539a260a   2017-12-19        2017-12-21   \n",
       "823384   00020785-d3b3-3ffd-9d1a-4be3539a260a   2018-02-14        2018-02-16   \n",
       "649449   00020785-d3b3-3ffd-9d1a-4be3539a260a   2017-11-08        2017-11-10   \n",
       "...                                       ...          ...               ...   \n",
       "645222   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-01        2017-11-03   \n",
       "555746   fffbf904-08c2-3096-ba13-619e749c3900   2017-10-12        2017-10-16   \n",
       "544288   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-04        2017-11-07   \n",
       "229462   fffbf904-08c2-3096-ba13-619e749c3900   2017-10-15        2017-10-17   \n",
       "473283   fffbf904-08c2-3096-ba13-619e749c3900   2018-03-24        2018-03-26   \n",
       "229399   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-22        2017-11-24   \n",
       "493185   fffbf904-08c2-3096-ba13-619e749c3900   2018-02-11        2018-02-12   \n",
       "117866   fffbf904-08c2-3096-ba13-619e749c3900   2017-10-22        2017-10-24   \n",
       "1082042  fffbf904-08c2-3096-ba13-619e749c3900   2017-10-11        2017-10-13   \n",
       "644244   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-04        2017-11-07   \n",
       "1111354  fffbf904-08c2-3096-ba13-619e749c3900   2017-12-17        2017-12-19   \n",
       "90860    fffbf904-08c2-3096-ba13-619e749c3900   2017-09-25        2017-09-27   \n",
       "239097   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-10        2017-11-14   \n",
       "1084897  fffbf904-08c2-3096-ba13-619e749c3900   2017-11-12        2017-11-14   \n",
       "373818   fffbf904-08c2-3096-ba13-619e749c3900   2017-12-17        2017-12-19   \n",
       "658278   fffbf904-08c2-3096-ba13-619e749c3900   2017-12-26        2017-12-28   \n",
       "592274   fffbf904-08c2-3096-ba13-619e749c3900   2017-10-27        2017-10-31   \n",
       "331747   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-16        2017-11-20   \n",
       "1127807  fffbf904-08c2-3096-ba13-619e749c3900   2018-03-31        2018-04-02   \n",
       "1126213  fffbf904-08c2-3096-ba13-619e749c3900   2018-01-16        2018-01-18   \n",
       "1174615  fffbf904-08c2-3096-ba13-619e749c3900   2018-02-11        2018-02-12   \n",
       "698548   fffbf904-08c2-3096-ba13-619e749c3900   2018-01-29        2018-01-30   \n",
       "97689    fffbf904-08c2-3096-ba13-619e749c3900   2018-03-11        2018-03-12   \n",
       "1094573  fffbf904-08c2-3096-ba13-619e749c3900   2018-03-17        2018-03-19   \n",
       "527526   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-29        2017-12-01   \n",
       "460644   fffbf904-08c2-3096-ba13-619e749c3900   2017-12-04        2017-12-06   \n",
       "136145   fffbf904-08c2-3096-ba13-619e749c3900   2017-10-22        2017-10-24   \n",
       "866111   fffbf904-08c2-3096-ba13-619e749c3900   2018-03-03        2018-03-05   \n",
       "760959   fffbf904-08c2-3096-ba13-619e749c3900   2017-12-26        2017-12-28   \n",
       "425827   fffbf904-08c2-3096-ba13-619e749c3900   2017-11-01        2017-11-03   \n",
       "\n",
       "          style        sku  days_rented  \n",
       "97471     ASR10    ASR10_M            9  \n",
       "853625    DRW13    DRW13_M            7  \n",
       "253129    TNT24    TNT24_8            9  \n",
       "1151198   PK213    PK213_M            7  \n",
       "1211566    SHL2     SHL2_M           35  \n",
       "1160524   CUP18    CUP18_M           35  \n",
       "1201341   CED42   CED42_44           19  \n",
       "648411    BSH10    BSH10_2            9  \n",
       "351339    JWG28   JWG28_10            9  \n",
       "891703    DL104    DL104_L            9  \n",
       "740478    BM497    BM497_8            7  \n",
       "671079    AMU87    AMU87_M           15  \n",
       "538604    WVG52    WVG52_M           15  \n",
       "757634     EQ63     EQ63_L           15  \n",
       "595894     DL79     DL79_8            7  \n",
       "756896    PPC32    PPC32_M           15  \n",
       "233756     SB39    SB39_40            7  \n",
       "901500     ASR8     ASR8_S            3  \n",
       "828656   DVF188  DVF188_XS           58  \n",
       "681417    KPL27    KPL27_S           31  \n",
       "680314    WVG53   WVG53_XS           13  \n",
       "784437     FZ16    FZ16_XS           35  \n",
       "602499     BRA5    BRA5_XS           12  \n",
       "674034     DRW4    DRW4_XS           14  \n",
       "356137    JWG19   JWG19_XS           28  \n",
       "598892     MRR3    MRR3_XS           14  \n",
       "1170765   ZDV16   ZDV16_XS            7  \n",
       "743433    ML216   ML216_XS           12  \n",
       "823384    FNP23    FNP23_2           48  \n",
       "649449    WVG64    WVG64_S           13  \n",
       "...         ...        ...          ...  \n",
       "645222     JE67     JE67_S            1  \n",
       "555746    CUP10    CUP10_S            1  \n",
       "544288   DVF123   DVF123_2            2  \n",
       "229462    CVN58   CVN58_36            1  \n",
       "473283     TH88    TH88_2R            4  \n",
       "229399    TT150    TT150_2            1  \n",
       "493185     RZ54     RZ54_2            4  \n",
       "117866    RT115    RT115_2            2  \n",
       "1082042    DAG1    DAG1_XS            1  \n",
       "644244    NM297    NM297_S            2  \n",
       "1111354     RV8      RV8_2            6  \n",
       "90860     AMU55  AMU55_XSR            6  \n",
       "239097     TLA9     TLA9_S            2  \n",
       "1084897   AMU71    AMU71_S            2  \n",
       "373818    RT107    RT107_2            6  \n",
       "658278     BBC2    BBC2_XS            5  \n",
       "592274     LVF7     LVF7_S            1  \n",
       "331747     FP66     FP66_S            1  \n",
       "1127807    BBC3    BBC3_XS            4  \n",
       "1126213    PTS7    PTS7_XS           10  \n",
       "1174615   JOA35    JOA35_S            4  \n",
       "698548     TMO9     TMO9_S            4  \n",
       "97689     PK174    PK174_0            4  \n",
       "1094573   MST14    MST14_S            4  \n",
       "527526    CUP11   CUP11_XS            2  \n",
       "460644    BM470   BM470_2R            1  \n",
       "136145    EF184    EF184_2            2  \n",
       "866111    AJY11    AJY11_S            6  \n",
       "760959     DVN3     DVN3_S            4  \n",
       "425827    TB198    TB198_2            1  \n",
       "\n",
       "[1228395 rows x 7 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.sort_values('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_attr['bmi'] = (user_attr['weight_lbs'] / user_attr['height_in'].pow(2))*703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_attr.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(g.index)\n",
    "user_attr.set_index('user_id', inplace=True)\n",
    "df = df.join(user_attr,on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(60 - df.height_in.min()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATE_FRMT = \"%Y-%m-%d\"\n",
    "def to_dates(df, cols):\n",
    "    _df = df.copy()\n",
    "    for col in cols:\n",
    "        _df[col] = pd.to_datetime(df[col], format=DATE_FRMT)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders\n",
    "\n",
    " - 1231230 total records, only 1228395 are unique order_ids (~3000 duplicates)\n",
    " - 35000 unique user_ids (top has ~ 300 orders)\n",
    " - ordered_date between 2017-01-01 and 2018-03-31\n",
    " - rental begins between 2017-01-04 and 2018-07-14 (about 1.5 years of data)\n",
    " - 4000 unique styles, top 1551\n",
    " - 24167 unique skus top 556\n",
    " - no missing values\n",
    " \n",
    " # Questions\n",
    " - Why duplicate order_ids?  Are they full-row duplicates (Yes)\n",
    " - distribution of user order frequency, how many repeat interactions\n",
    " - Last date for ordered_date id 2018-03-31, last date for rental begins is 2018-07-14 (does this imply 3.5 month lag?)\n",
    " - does days_rented correlate to satisfaction / fit\n",
    " \n",
    " ## Collobartive Filtering \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = to_dates(orders, ['ordered_date', 'rental_begin_date'])\n",
    "orders.drop_duplicates(inplace=True)\n",
    "orders.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_orders_plots(df):\n",
    "    _df = df.copy()\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    _df[['user_id']].apply(pd.value_counts).hist(ax=ax)\n",
    "    ax.set_title(\"Histogram of order frequency for users\")\n",
    "\n",
    "    \n",
    "    _df = _df.set_index(\"ordered_date\").sort_index()\n",
    "    _df['order_cnt'] = 1\n",
    "    _df['cust_cnt'] = ~_df['user_id'].duplicated()\n",
    "    _df['order_cum'] = _df['order_cnt'].cumsum()\n",
    "    _df['cust_cum'] = _df['cust_cnt'].cumsum()\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    _df.order_cnt.resample('M', convention='start').sum().plot(ax=ax)\n",
    "    ax.set_title(\"New Orders by Month\")\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    _df.cust_cnt.resample('M', convention='start').sum().plot(ax=ax)\n",
    "    ax.set_title(\"New Customers by Month\")\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    _df.order_cum.resample('M', convention='start').max().plot(ax=ax)\n",
    "    ax.set_title(\"Cum. Growth in orders\")\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    _df.cust_cum.resample('M', convention='start').max().plot(ax=ax)\n",
    "    ax.set_title(\"Cum. Growth in custs\")\n",
    "\n",
    "make_orders_plots(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_reviews_data(reviews):\n",
    "\n",
    "    reviews.drop_duplicates(inplace=True)\n",
    "    reviews['did_you_wear_it'] = reviews['did_you_wear_it'].astype('category')\n",
    "\n",
    "    like_it_cat_type = CategoricalDtype(categories=['just_okay', 'liked_it', 'loved_it'], ordered=True)\n",
    "    reviews['how_did_you_like_it'] = reviews['how_did_you_like_it'].astype(like_it_cat_type)\n",
    "\n",
    "    reviews['didnt_fit'] = reviews['didnt_fit'].astype('category')\n",
    "    reviews['size_overall'] = reviews['size_overall'].astype('category')\n",
    "    reviews['size_chest'] = reviews['size_chest'].astype('category')\n",
    "    reviews['size_waist'] = reviews['size_waist'].astype('category')\n",
    "    reviews['size_waist.1'] = reviews['size_waist.1'].astype('category')\n",
    "    reviews['length'] = reviews['length'].astype('category')\n",
    "    reviews['not_flattering'] = reviews['not_flattering'].astype('category')\n",
    "    reviews['not_my_style'] = reviews['not_my_style'].astype('category')\n",
    "    reviews['other_issue'] = reviews['other_issue'].astype('category')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
